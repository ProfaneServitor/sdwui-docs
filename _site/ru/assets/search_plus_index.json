{"/sdwui-docs/cli/": {
    "title": "Аргументы и настройки командной строки",
    "keywords": "Guides",
    "url": "/sdwui-docs/cli/",
    "body": "webui-пользователь Рекомендуемый способ настроить запуск программы — отредактировать файлы webui-user.bat (Windows) и webui-user.sh (Linux): set PYTHON позволяет установить собственный путь Python Пример: set PYTHON=b:/soft/Python310/Python.exe set VENV_DIR позволяет вам выбрать каталог для виртуальной среды. По умолчанию это venv. Специальное значение - запускает скрипт без создания виртуальной среды. Пример: set VENV_DIR=C:\\run\\var\\run создаст venv в каталоге C:\\run\\var\\run. Пример: set VENV_DIR=- запускает программу, используя системный python. set COMMANDLINE_ARGS, устанавливающий аргументы командной строки webui.py, запускается с Пример: set COMMANDLINE_ARGS=--ckpt a.ckpt использует модель a.ckpt вместо model.ckpt Аргументы командной строки Запуск онлайн Используйте опцию --share для запуска онлайн. Вы получите ссылку xxx.app.gradio. Это предполагаемый способ использования программы в коллаборациях. Вы можете настроить аутентификацию для указанного общего экземпляра gradio с флагом --gradio-auth username:password, при необходимости указав несколько наборов имен пользователей и паролей, разделенных запятыми. Используйте --listen, чтобы заставить сервер прослушивать сетевые соединения. Это позволит компьютерам в локальной сети получить доступ к пользовательскому интерфейсу, а если вы настроите переадресацию портов, также компьютерам в Интернете. Используйте --port xxxx, чтобы заставить сервер прослушивать определенный порт, где xxxx является желаемым портом. Помните, что для всех портов ниже 1024 требуются права root/admin, по этой причине рекомендуется использовать порт выше 1024. По умолчанию используется порт 7860, если он доступен. Все аргументы командной строки | Аргумент Команда | Значение | По умолчанию | Описание | | —————- | —– | ——- | ———– | КОНФИГУРАЦИЯ       -ч, –помощь Нет Ложь показать это справочное сообщение и выйти –конфигурация КОНФИГУРАЦИЯ configs/stable-diffusion/v1-inference.yaml путь к конфигу, который строит модель –ckpt СКРТ модель.ckpt путь к контрольной точке модели стабильной диффузии; если указано, то эта контрольная точка будет добавлена ​​в список контрольных точек и загружена –ckpt-каталог CKPT_DIR Нет Путь к каталогу со стабильными контрольными точками распространения –gfpgan-каталог GFPGAN_DIR ГФГАН/ Каталог GFPGAN –gfpgan-модель GFPGAN_MODEL Имя файла модели GFPGAN   –codeformer-models-путь CODEFORMER_MODELS_PATH модели/Кодформер/ Путь к каталогу с файлами моделей codeformer. –gfpgan-модели-путь GFPGAN_MODELS_PATH модели/GFPGAN Путь к каталогу с файлами модели GFPGAN. –esrgan-models-путь ESRGAN_MODELS_PATH модели/ЕСРГАН Путь к каталогу с файлами модели ESRGAN. –bsrgan-models-путь BSRGAN_MODELS_PATH модели/BSRGAN Путь к каталогу с файлами модели BSRGAN. –realesrgan-models-путь REALESRGAN_MODELS_PATH модели/RealESRGAN Путь к каталогу с файлами модели RealESRGAN. –scunet-модели-путь SCUNET_MODELS_PATH модели/ScuNET Путь к каталогу с файлами модели ScuNET. –swinir-модели-путь SWINIR_MODELS_PATH модели/SwinIR Путь к каталогу с файлами моделей SwinIR и SwinIR v2. –ldsr-модели-путь LDSR_MODELS_PATH модели/ЛДСР Путь к каталогу с файлами моделей LDSR. –клип-модели-путь CLIP_MODELS_PATH Нет Путь к каталогу с файлами модели CLIP. –vae-путь ВАЕ_ПУТЬ Нет Путь к модели вариационных автоэнкодеров –embeddings-dir EMBEDDINGS_DIR вложения/ каталог embeddings для инверсии текста (по умолчанию: embeddings) –гиперсетевой-каталог ГИПЕРСЕТЬ_КАТАЛОГ модели/гиперсети/ каталог гиперсети –localizations-dir ЛОКАЛИЗАЦИИ_КАТАЛОГ локализации/ каталог локализаций –стили-файл СТИЛЬ_ФАЙЛ стили.csv имя файла для стилей –ui-файл конфигурации UI_CONFIG_FILE пользовательский интерфейс-config.json имя файла для настройки пользовательского интерфейса –no-progressbar-скрытие Нет Ложь не скрывать индикатор выполнения в пользовательском интерфейсе градиента (мы скрываем его, потому что он замедляет ML, если у вас есть аппаратное ускорение в браузере) –max-количество партий MAX_BATCH_COUNT 16 максимальное значение счетчика пакетов для пользовательского интерфейса –ui-файл настроек UI_SETTINGS_FILE конфиг.json имя файла для использования в настройках пользовательского интерфейса –разрешить-код Нет Ложь разрешить выполнение пользовательского скрипта из webui –поделиться Нет Ложь используйте share=True для градиента и сделайте пользовательский интерфейс доступным через их сайт (у меня не работает, но вам может повезти) –слушать Нет Ложь запустить градио с 0.0.0.0 в качестве имени сервера, позволяющего отвечать на сетевые запросы –порт ПОРТ 7860 запустить gradio с заданным портом сервера, вам нужны права root/admin для портов &lt; 1024, по умолчанию 7860, если доступно –hide-ui-dir-config Нет Ложь скрыть конфигурацию каталога от webui –заморозить-настройки Нет Ложь отключить редактирование настроек –enable-insecure-extension-access Нет Ложь включить вкладку расширений независимо от других параметров –градио-отладка Нет Ложь запустить градио с параметром –debug –градио-авторизация GRADIO_AUTH Нет установить градиентную аутентификацию, например «имя пользователя: пароль»; или несколько с разделителями-запятыми, например “u1:p1,u2:p2,u3:p3” –gradio-img2img-инструмент {цветной эскиз, редактор} редактор инструмент для загрузки изображений градио: может быть как редактор для ктоппинга, так и цветной эскиз для рисования –disable-console-progressbars Нет Ложь не выводить индикаторы выполнения на консоль –enable-console-prompts Нет Ложь print запрашивает консоль при создании с помощью txt2img и img2img –апи Нет Ложь запустить webui через API –новебуи Нет Ложь запускать только API, без пользовательского интерфейса –ui-режим отладки Нет Ложь Не загружайте модель для быстрого запуска пользовательского интерфейса –идентификатор устройства ИДЕНТИФИКАТОР_УСТРОЙСТВА Нет Выберите устройство CUDA по умолчанию для использования (ранее может потребоваться экспорт CUDA_VISIBLE_DEVICES=0,1 и т. д.) –администратор Нет Ложь Права администратора ЭФФЕКТИВНОСТЬ       –xformers Нет Ложь включить xformers для слоев перекрестного внимания –reinstall-xformers Нет Ложь принудительно переустановите xformers. Полезно для обновления, но удалите его после обновления, иначе вы будете постоянно переустанавливать xformers. –force-enable-xformers Нет Ложь включите xformers для слоев перекрестного внимания независимо от того, считает ли проверяющий код, что вы можете его запустить; ** не сообщайте об ошибках, если это не работает ** –opt-split-внимание Нет Ложь force-включает оптимизацию уровня перекрестного внимания Doggettx. По умолчанию он включен для систем с поддержкой cuda. –opt-split-invokeai Нет Ложь force-включает оптимизацию уровня перекрестного внимания InvokeAI. По умолчанию он включен, когда cuda недоступен. –opt-split-внимание-v1 Нет Ложь включить старую версию оптимизации разделения внимания, которая не потребляет всю VRAM, которую может найти –opt-каналыпоследний Нет Ложь изменить тип памяти для стабильной диффузии на последние каналы –disable-opt-split-attention Нет Ложь принудительно отключает оптимизацию уровня перекрестного внимания –использовать-процессор {all, sd, опрос, gfpgan, bsrgan, esrgan, scunet, codeformer} Нет использовать ЦП в качестве устройства-факела для указанных модулей –без половины Нет Ложь не переключать модель на 16-битные числа с плавающей запятой –точность {полный, автозапуск} автотрансляция оценить с этой точностью –no-half-vae Нет Ложь не переключать модель VAE на 16-битные числа с плавающей запятой –медврам Нет Ложь включить стабильную оптимизацию диффузионной модели, чтобы пожертвовать небольшой скоростью ради низкого использования VRM –лоуврам Нет Ложь включить стабильную оптимизацию диффузионной модели, чтобы пожертвовать большой скоростью ради очень низкого использования VRM –lowram Нет Ложь загружать стабильные веса контрольных точек диффузии во VRAM вместо RAM –always-batch-cond-uncond Нет Ложь отключает пакетирование с условием/неусловием, которое включено для экономии памяти с –medvram или –lowvram ОСОБЕННОСТИ       –автозапуск Нет Ложь открыть URL-адрес webui в системном браузере по умолчанию при запуске –тема Нет Снять открыть webui с указанной темой (“светлая” или “темная”). Если не указано, использует тему браузера по умолчанию –use-textbox-seed Нет Ложь использовать текстовое поле для начальных значений в пользовательском интерфейсе (без вверх/вниз, но можно вводить длинные начальные значения) –disable-safe-unpickle Нет Ложь отключить проверку моделей pytorch на наличие вредоносного кода –нгрок НГРОК Снять ngrok authtoken, альтернатива gradio –share –ngrok-регион NGROK_REGION Снять Регион, в котором должен запускаться ngrok. НЕФУНКЦИОНАЛЬНЫЕ ВАРИАНТЫ       –show-negative-prompt Нет Ложь ничего не делает –дипданбору Нет Ложь ничего не делает –выгрузить-gfpgan Нет Ложь ничего не делает."
  },"/sdwui-docs/contributing/": {
    "title": "Содействие",
    "keywords": "development",
    "url": "/sdwui-docs/contributing/",
    "body": "функции Пул-реквесты Чтобы внести свой вклад, клонируйте репозиторий, внесите свои изменения, зафиксируйте и отправьте в свой клон, а также отправьте запрос на извлечение. Убедитесь, что ваши изменения ничего не сломают, запустив тесты. Если вы добавляете много кода, подумайте о том, чтобы внести свой вклад в виде расширения и указывать только небольшие изменения, необходимые в основном коде, чтобы сделать расширение возможным. Если вы вносите изменения в используемые библиотеки или сценарий установки, вы должны убедиться, что они работают с установкой Windows по умолчанию с нуля. Если вы не можете проверить, работает ли это (из-за вашей ОС или чего-то еще), не вносите эти изменения (за возможным исключением изменений, которые явно защищены от выполнения в Windows с помощью ifs или чего-то еще). Стиль кода В основном я следую стилю кода, предложенному PyCharm, за исключением отключенного ограничения длины строки. Пожалуйста, не отправляйте PR, в которых вы просто берете существующие строки и переформатируете их без изменения того, что они делают. Построено В какой-то момент Gradio захотели добавить этот раздел, чтобы представить свой проект в разделе вкладов, которого у меня в то время не было, так что вот он. Для Gradio ознакомьтесь с документами, чтобы внести свой вклад: Есть проблема или запрос функции с Gradio? откройте запрос о проблеме/функции на github для поддержки: https://github.com/gradio-app/gradio/issues"
  },"/sdwui-docs/custom-filenames/": {
    "title": "Имя файла и подкаталог пользовательских изображений",
    "keywords": "Guides",
    "url": "/sdwui-docs/custom-filenames/",
    "body": "следующая информация относится к имени файла изображения и имени подкаталога, а не к Пути для сохранения\\Выходные каталоги По умолчанию пользовательский интерфейс Wub сохраняет изображения в выходных каталогах со структурой имени файла число-seed-[prompt_spaces] 01234-987654321-((masterpiece)), ((best quality)), ((illustration)), extremely detailed,style girl.png По желанию пользователя можно использовать другое имя файла изображения и дополнительный подкаталог. Шаблон имени файла изображения можно настроить в разделе. вкладка настроек &gt; Сохранение изображений/сеток &gt; Шаблон имени файла изображений Подкаталог можно настроить в настройках. вкладка настроек &gt; Сохранение в каталоге &gt; Шаблон имени каталога Паттены Web-Ui предоставляет несколько шаблонов, которые можно использовать в качестве заполнителей для вставки информации в имя файла или подкаталог. пользователь может связать эти шаблоны вместе, образуя имя файла, которое подходит для его варианта использования. | Узор | Описание | Пример | |——————————–|—————- ————————————–|———– ————————————————– ————————————————– ————————| | [семя] | Семена | 1234567890 | | [шаги] | Шаги | 20 | | [конфигурация] | шкала CFG | 7 | | [сэмплер] | Метод выборки | Эйлер а | | [model_hash] | Хэш модели | 7460a6fa | | [ширина] | Ширина изображения | 512 | | [высота] | Высота изображения | 512 | | [стили] | Название выбранных стилей | мое имя стиля | | [дата] | Дата компьютера в формате ISO | 24.10.2022 | | [дата и время] | Дата и время в “%Y%m%d%H%M%S” | 20221025013106 | | [дата/время&lt;Формат&gt;] | Дата и время в указанном &lt;Format&gt; | [datetime&lt;%Y%m%d_%H%M%S_%f&gt;]20221025014350_733877 | | [datetime&lt;Format&gt;&lt;TimeZone&gt;] | Дата и время в определенном &lt;часовом поясе&gt; в указанном &lt;формате&gt; | [datetime&lt;%Y%m%d%H%M%S_%f&gt;&lt;Азия/Токио&gt;]&lt;br&gt;20221025_014350_733877 | | [prompt_no_styles] | Подскажите без стилей | 1гир, пробел, ((очень важно)), [не важно], (какое-то значение_1.5), (что угодно), конец&lt;br&gt; | | [prompt_spaces] | Подскажите со стилями | 1гир, пробел, ((очень важно)), [не важно], (какое-то значение_1.5), (что угодно), конец&lt;br&gt;, (((кристаллы текстуры Волос)))，((( | | [подсказка] | Подсказка со стилями, пробел заменен на _ | 1gir,\\_\\_\\_white_space,\\_((очень\\_важно)),\\_[не\\_важно],\\_(какое-то\\_значение\\_1.5),\\_(что угодно),\\_the\\_end, \\_(((crystals_texture_Hair)))，((( | | [слова подсказки]` | Подсказка со стилями, скобками и запятыми удалена | 1gir пустое пространство очень важно не важно какое-то значение 1 5 независимо от того, что конец кристаллы текстуры волос ， очень подробно | Сведения о форматировании даты и времени См. документацию по Python для получения более подробной информации о Кодах формата. Дата и время Информация о часовом поясе Ссылка Список часовых поясов для списка допустимых часовых поясов. Если &lt;Format&gt; пусто или недействительно, будет использоваться формат времени по умолчанию “%Y%m%d%H%M%S” совет: вы можете использовать дополнительные символы внутри &lt;Format&gt; для пунктуации, например _ - Если &lt;TimeZone&gt; пусто или недействительно, будет использоваться системный часовой пояс по умолчанию. Подсказки и стиль, используемые для приведенных выше примеров [prompt] Быстрый: 1gir, white space, ((very important)), [not important], (some value:1.5), (whatever), the end Выбранные стили: (((crystals texture Hair)))，(((((extremely detailed CG))))),((8k_wallpaper)) примечание: упомянутые выше «стили» относятся к двум раскрывающимся меню под кнопкой «Создать». если подсказки слишком длинные, они будут короткими это связано с тем, что компьютер имеет максимальную длину файла Добавить/удалить номер к имени файла при сохранении вы можете удалить префикс номера сняв флажок под Настройки &gt; Сохранение изображений/сеток &gt; Добавить номер к имени файла при сохранении с префиксом номера 00123-`987654321-((masterpiece)).png без префикса номера 987654321-((masterpiece)).png Осторожность Назначение номера префикса — гарантировать, что имя сохраненного файла изображения будет уникальным. Если вы решите не использовать номер префикса, убедитесь, что ваш шаблон будет генерировать уникальное имя файла, В противном случае файлы могут быть перезаписаны. Как правило, дата и время с точностью до секунд должны гарантировать уникальность имени файла. [datetime&lt;%Y%m%d_%H%M%S&gt;]-[seed] 20221025_014350-281391998.png Но некоторые Пользовательские скрипты могут генерировать несколько изображений с использованием одного и того же начального значения в одной партии, в этом случае безопаснее также использовать %f для микросекунды как десятичное число, дополненное нулями до 6 цифр. [datetime&lt;%Y%m%d_%H%M%S_%f&gt;]-[seed] 20221025_014350_733877-281391998.png Примеры шаблонов имен файлов Если вы используете Web-Ui на нескольких компьютерах, скажем, в Google Colab и на своем собственном компьютере, вы можете использовать имя файла со временем в качестве префикса. это для того, чтобы при скачивании фолов можно было положить их в ту же папку. Кроме того, поскольку вы не знаете, какой часовой пояс использует Google Colab, вам нужно указать часовой пояс. [datetime&lt;%Y%m%d_%H%M%S_%f&gt;&lt;Asia/Tokyo&gt;]-[seed]-[prompt_words] 20221025_032649_058536-3822510847-1girl.png Также может быть полезно установить дату в подкаталоге, чтобы в одной папке не было слишком много изображений. [datetime&lt;%Y-%m-%d&gt;&lt;Asia/Tokyo&gt;] 2022-10-25"
  },"/sdwui-docs/custom-scripts/": {
    "title": "Пользовательские скрипты",
    "keywords": "Guides",
    "url": "/sdwui-docs/custom-scripts/",
    "body": "Установка и использование пользовательских скриптов Чтобы установить пользовательские сценарии, поместите их в каталог scripts и нажмите кнопку Обновить пользовательский сценарий внизу на вкладке настроек. Пользовательские сценарии появятся в раскрывающемся меню в левом нижнем углу на вкладках txt2img и img2img после установки. Ниже приведены некоторые известные пользовательские сценарии, созданные пользователями веб-интерфейса: Пользовательские сценарии от пользователей Улучшенная матрица подсказок https://github.com/ArrowM/auto1111-улучшенная-подсказка-матрица Этот скрипт advanced-prompt-matrix изменен для поддержки пакетного подсчета. Сетки не создаются. Применение: Используйте &lt; &gt;, чтобы создать группу альтернативных текстов. Разделяйте параметры текста символом |. Можно использовать несколько групп и несколько вариантов. Например: Ввод &lt;корги|кошка&gt; в &lt;очках|шляпе&gt; Будет выведено 4 подсказки: «корги в очках», «корги в шляпе», «кот в очках», «кот в шляпе». При использовании количества пакетов &gt; 1 каждый вариант подсказки будет создан для каждого начального числа. размер пакета игнорируется. txt2img2img https://github.com/ThereforeGames/txt2img2img Значительно улучшите возможность редактирования любого персонажа/объекта, сохранив при этом их сходство. Основной мотивацией для этого скрипта является улучшение возможности редактирования вложений, созданных с помощью текстовой инверсии. (будьте осторожны с клонированием, так как оно немного проверено) Пример: (Нажмите, чтобы развернуть:) txt2маска https://github.com/ThereforeGames/txt2mask Позволяет указать маску рисования с текстом, а не с кистью. Пример: (Нажмите, чтобы развернуть:) Интерфейс рисования маски https://github.com/dfaker/stable-diffusion-webui-cv2-external-masking-script Предоставляет локальное всплывающее окно на основе CV2, которое позволяет добавить маску перед обработкой. Пример: (Нажмите, чтобы развернуть:) Img2img видео https://github.com/memes-forever/Stable-diffusion-webui-video Используя img2img, генерирует картинки одну за другой. Путешествие с семенами https://github.com/yownas/seed_travel Выберите два (или более) начальных значения и сгенерируйте последовательность изображений, интерполируя их. При желании, пусть он создаст видео результата. Пример того, что вы можете с ним сделать: https://www.youtube.com/watch?v=4c71iUclY4U Другой пример пользователя: Расширенное смешивание семян https://github.com/amotile/stable-diffusion-backend/tree/master/src/process/implementations/automatic1111_scripts Этот сценарий позволяет вам основывать начальный шум на нескольких взвешенных начальных значениях. Бывший. seed1:2, seed2:1, seed3:1 Веса нормализованы, поэтому вы можете использовать больше, как указано выше, или вы можете использовать числа с плавающей запятой: Бывший. seed1: 0,5, seed2: 0,25, seed3: 0,25 Быстрое смешивание https://github.com/amotile/stable-diffusion-backend/tree/master/src/process/implementations/automatic1111_scripts Этот скрипт позволяет вам объединять несколько взвешенных подсказок, математически комбинируя их текстовые вложения перед созданием изображения. Бывший. Кристалл, содержащий элементаль {огонь|лед} Он поддерживает вложенные определения, поэтому вы также можете сделать это: Кристалл, содержащий элементаль {{огонь:5|лед}|земля} Аниматор https://github.com/Аниматор-Анон/Аниматор Базовый скрипт img2img, который выгружает кадры и создает видеофайл. Подходит для создания интересного зума в фильмах с деформацией, но в настоящее время не более того. Секвенсор параметров https://github.com/rewbs/sd-parseq Создавайте видео с жестким контролем и гибкой интерполяцией по многим параметрам Stable Diffusion (таким как начальное число, масштаб, быстрые веса, сила шумоподавления…), а также параметрам входной обработки (таким как масштабирование, панорамирование, 3D-поворот…) Альтернативные расписания шума https://gist.github.com/dfaker/f88aa62e3a14b559fe4e5f6b345db664 Использует альтернативные генераторы для графика сигма сэмплера. Предоставляет доступ к графикам Karras, Exponential и Variance Preserving из crowsonkb/k-diffusion вместе с их параметрами. Vid2Vid https://github.com/Filarius/stable-diffusion-webui/blob/master/scripts/vid2vid.py Из реального видео, img2img кадры и склеить их вместе. Не распаковывает кадры на жесткий диск. Txt2VectorGraphics https://github.com/GeorgLegato/Txt2Vectorgraphics Создавайте настраиваемые масштабируемые значки из подсказок в формате SVG или PDF. Пример: (Нажмите, чтобы развернуть:) | приглашение |PNG |SVG | | :-------- | :-----------------: | :----------------------------------: | | Счастливый Эйнштейн | | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193370379-2680aa2a-f460-44e7-9c4e-592cf096de71.svg\" width=30%/&gt; | | Скоростной спуск на горном велосипеде | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193371353-f0f5ff6f-12f7-423b-a481-f9bd119631dd.png\" width=40%/&gt; | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193371585-68dea4ca-6c1a-4d31-965d-c1b5f145bb6f.svg\" width=30%/&gt; | кофейная кружка в форме сердца | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193374299-98379ca1-3106-4ceb-bcd3-fa129e30817a.png\" width=40%/&gt; | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193374525-460395af-9588-476e-bcf6-6a8ad426be8e.svg\" width=30%/&gt; | | Наушники | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193376238-5c4d4a8f-1f06-4ba4-b780-d2fa2e794eda.png\" width=40%/&gt; | &lt;img src=\"https://user-images.githubusercontent.com/7210708/193376255-80e25271-6313-4bff-a98e-ba3ae48538ca.svg\" width=30%/&gt; | Переключение внимания https://github.com/yownas/shift-внимание Создайте последовательность изображений, переключающих внимание в подсказке. Этот сценарий позволяет указать диапазон веса жетонов в подсказке, а затем сгенерировать последовательность изображений, переходя от первого ко второму. Зацикливание и наложение https://github.com/DiceOwl/StableDiffusionStuff https://github.com/DiceOwl/StableDiffusionStuff/blob/main/loopback_superimpose.py Смешивает вывод img2img с исходным входным изображением с силой альфа. Результат снова загружается в img2img (в цикле&gt;=2), и эта процедура повторяется. Имеет тенденцию повышать резкость изображения, улучшать согласованность, снижать творческий потенциал и уменьшать мелкие детали. Интерполировать https://github.com/DiceOwl/StableDiffusionStuff https://github.com/DiceOwl/StableDiffusionStuff/blob/main/interpolate.py Скрипт img2img для создания промежуточных изображений. Позволяет два входных изображения для интерполяции. Дополнительные функции показаны в readme. Выполнить n раз https://gist.github.com/camenduru/9ec5f8141db9902e375967e93250860f Выполнить n раз со случайным начальным числом. Расширенный цикл обратной связи https://github.com/Extraltodeus/advanced-loopback-for-sd-webui Динамическое масштабирование с изменением параметров и быстрым переключением среди других функций! быстрое преобразование https://github.com/feffy380/prompt-morph Создавайте последовательности морфинга с помощью Stable Diffusion. Интерполируйте между двумя или более подсказками и создавайте изображение на каждом шаге. Использует новое ключевое слово AND и может дополнительно экспортировать последовательность как видео. оперативная интерполяция https://github.com/EugeoSynthesisThirtyTwo/prompt-interpolation-script-for-sd-webui С помощью этого сценария вы можете выполнять интерполяцию между двумя подсказками (используя ключевое слово «И») и генерировать столько изображений, сколько хотите. Вы также можете создать GIF с результатом. Работает как для txt2img, так и для img2img. Пример: (Нажмите, чтобы развернуть:) ![gif](https://user-images.githubusercontent.com/24735555/195470874-afc3dfdc-7b35-4b23-9c34-5888a4100ac1.gif) Ассиметричная мозаика https://github.com/tjm35/асимметричная плитка-sd-webui/ Управляйте горизонтальной/вертикальной бесшовной мозаикой независимо друг от друга. Пример: (Нажмите, чтобы развернуть:) Силовая симметрия https://gist.github.com/1ort/2fe6214cf1abe4c07087aac8d91d0d8a см. https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2441 применяет симметрию к изображению каждые n шагов и отправляет результат далее в img2img. Пример: (Нажмите, чтобы развернуть:) SD-скрытое зеркалирование https://github.com/dfaker/SD-латентное-зеркалирование Применяет зеркальное отражение и отражение к скрытым изображениям для создания чего угодно, от тонких сбалансированных композиций до идеальных отражений. Пример: (Нажмите, чтобы развернуть:) txt2палитра https://github.com/1ort/txt2palette Создавайте палитры по текстовому описанию. Этот скрипт берет сгенерированные изображения и преобразует их в цветовые палитры. Пример: (Нажмите, чтобы развернуть:) СтилиСтрелки https://github.com/some9000/StylePile Простой способ смешивания и сопоставления элементов с подсказками, которые влияют на стиль результата. Пример: (Нажмите, чтобы развернуть:) Сценарий графика XYZ https://github.com/xrpgame/xyz_plot_script Создает файл .html для интерактивного просмотра набора изображений. Используйте колесо прокрутки или клавиши со стрелками для перемещения по оси Z. Пример: (Нажмите, чтобы развернуть:) xyz-сюжетная сетка https://github.com/Gerschel/xyz-сюжет-сетка Поместите xyz_grid.py в папку скриптов рядом с другими скриптами. Работает как график x/y, как и следовало ожидать, но теперь имеет z. Работает так, как вы ожидаете, с легендами сетки. Пример: (Нажмите, чтобы развернуть:) Расширенная сетка XY https://github.com/0xALIVEBEEF/Расширенная-XY-сетка Пользовательский скрипт для стабильной диффузии-webui AUTOMATIC1111, который добавляет больше возможностей в стандартную сетку xy: Multitool: позволяет использовать несколько параметров на одной оси, теоретически позволяет регулировать неограниченное количество параметров в одной координатной сетке. Настраиваемая матрица подсказок Группировать файлы в каталоге S/R Placeholder — замените значение-заполнитель (первое значение в списке параметров) на нужные значения. Добавить PNGinfo в изображение сетки Пример: (Нажмите, чтобы развернуть:) Примеры изображений: Подсказка: \"Дарт Вейдер едет на велосипеде, модификатор\"; X: Multitool: \"Подсказка S/R: велосипед, мотоцикл | Масштаб CFG: 7.5, 10 | Подсказка S/R Placeholder: модификатор, 4k, artstation\"; Y: Multitool: «Сэмплер: Эйлер, Эйлер a | Шаги: 20, 50» Автодополнение тега Booru https://github.com/DominikDoom/a1111-sd-webui-tagcomplete Отображает подсказки автозаполнения для тегов с досок «image booru», таких как Danbooru. Использует файлы CSV с локальными тегами и включает конфигурацию для настройки. Также поддерживает завершение для подстановочных знаков Встраивание в PNG https://github.com/dfaker/embedding-to-png-скрипт Преобразует существующие вложения в общедоступные версии изображений. Пример: (Нажмите, чтобы развернуть:) Альфа-канвас https://github.com/TKoestlerx/sdexperiments Закрасьте регион. Концепция бесконечного перекрашивания использовала в качестве основы два существующих скрипта перекрашивания из репозитория AUTOMATIC1111. Пример: (Нажмите, чтобы развернуть:) Случайная сетка https://github.com/lilly1987/AI-WEBUI-scripts-Random Произвольно введите значения сетки xy. Пример: (Нажмите, чтобы развернуть:) Основная логика аналогична графику x/y, только внутри тип x фиксируется как шаг, а тип y фиксируется как cfg. Генерирует значения x, равные количеству шагов (10) в диапазоне значений step1|2 (10-30) Генерирует столько значений x, сколько отсчетов cfg (10) в диапазоне значений cfg1|2 (6-15) Даже если вы перевернете ограничение диапазона 1|2 вверх дном, оно автоматически изменится. В случае значения cfg оно рассматривается как тип int, и десятичное значение не читается. Случайный https://github.com/lilly1987/AI-WEBUI-scripts-Random Повторить простое количество раз без сетки. Пример: (Нажмите, чтобы развернуть:) Эстетическая оценка стабильной диффузии https://github.com/grexzen/SD-Чад Оценивает ваши изображения. img2tiles https://github.com/arcanite24/img2tiles генерировать тайлы из базового изображения. Основан на высококлассном сценарии SD. Пример: (Нажмите, чтобы развернуть:) img2mosiac https://github.com/1ort/img2mosaic Создавайте мозаики из изображений. Скрипт разрезает изображение на тайлы и обрабатывает каждый тайл отдельно. Размер каждой плитки выбирается случайным образом. Пример: (Нажмите, чтобы развернуть:) Карты глубины https://github.com/thygate/stable-diffusion-webui-depthmap-script Этот скрипт является надстройкой для веб-интерфейса AUTOMATIC1111 Stable Diffusion, который создает «карты глубины» из сгенерированных изображений. Результат можно просматривать на 3D- или голографических устройствах, таких как VR-гарнитуры или дисплей lookglass, использовать в Render- или Game-Engine на плоскости с модификатором смещения и, возможно, даже на 3D-печати. . Пример: (Нажмите, чтобы развернуть:) Проверить мою подсказку https://github.com/Extraltodeus/test_my_prompt Вы когда-нибудь использовали очень длинную подсказку, полную слов, которые, как вы не уверены, действительно влияют на ваш имидж? Вы потеряли смелость попытаться удалить их один за другим, чтобы проверить, достойны ли их эффекты вашего мощного графического процессора? ХОРОШО, теперь вам не нужна смелость, так как этот сценарий был СДЕЛАН ДЛЯ ВАС! Он генерирует столько изображений, сколько слов в вашей подсказке (конечно, вы можете выбрать разделитель). Пример: (Нажмите, чтобы развернуть:) Здесь подсказка просто: «**банан, в огне, снег**», и, как вы можете видеть, он сгенерировал каждое изображение без каждого описания в нем. Вы также можете проверить свою отрицательную подсказку. Пиксель арт https://github.com/C10udburst/stable-diffusion-webui-скрипты Простой скрипт, который изменяет размер изображения на переменную величину, а также преобразует изображение для использования цветовой палитры заданного размера. Пример: (Нажмите, чтобы развернуть:) | Отключено | Включено x8, без изменения размера назад, без цветовой палитры | Включено x8, без цветовой палитры | Включена цветовая палитра x8, 16 | | :---: | :---: | :---: | :---: | |![предварительная версия](https://user-images.githubusercontent.com/18114966/201491785-e30cfa9d-c850-4853-98b8-11db8de78c8d.png) | ![предварительный просмотр](https://user-images.githubusercontent.com/18114966/201492204-f4303694-e98d-4ea3-8256-538a88ea26b6.png) | ![предварительная версия](https://user-images.githubusercontent.com/18114966/201491864-d0c0c9f1-e34f-4cb6-a68e-7043ec5ce74e.png) | ![предварительная версия](https://user-images.githubusercontent.com/18114966/201492175-c55fa260-a17d-47c9-a919-9116e1caa8fe.png) | [используемая модель](https://publicprompts.art/all-in-one-pixel-art-dreambooth-model/) ```text japanese pagoda with blossoming cherry trees, full body game asset, in pixelsprite style Steps: 20, Sampler: DDIM, CFG scale: 7, Seed: 4288895889, Size: 512x512, Model hash: 916ea38c, Batch size: 4 ``` Несколько гиперсетей https://github.com/antis0007/sd-webui-multiple-hypernetworks Добавляет возможность применять сразу несколько гиперсетей. Переопределяет функции перехвата, оптимизации и переадресации CrossAttention для последовательного применения нескольких гиперсетей с разными весами. Структура гиперсети (.hns)/Переменные Dropout/Monkey Patches https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension Добавляет возможность применять структуру гиперсети, определяя ее в файле .hns. см. здесь для получения подробной информации. Добавляет возможность использовать правильную переменную скорость отсева, например 0,05. Также устраняет проблемы с использованием гиперсети сразу после тренировки. Добавляет создание бета-гиперсети (выпадение) и бета-обучение, которое позволяет автоматически косинусный отжиг и использование исходных изображений без обрезки. Конфиг-пресеты https://github.com/Zyin055/Config-Presets-Script-OLD- Быстро меняйте настройки на вкладках txt2img и img2img, используя настраиваемый раскрывающийся список предустановленных значений. Пример: (Нажмите, чтобы развернуть:) Сохранение шагов процесса выборки Этот сценарий сохранит этапы процесса выборки в каталог. import os.path import modules.scripts as scripts import gradio as gr from modules import sd_samplers, shared from modules.processing import Processed, process_images class Script(scripts.Script): def title(self): return \"Save steps of the sampling process to files\" def ui(self, is_img2img): path = gr.Textbox(label=\"Save images to path\") return [path] def run(self, p, path): index = [0] def store_latent(x): image = shared.state.current_image = sd_samplers.sample_to_image(x) image.save(os.path.join(path, f\"sample-{index[0]:05}.png\")) index[0] += 1 fun(x) fun = sd_samplers.store_latent sd_samplers.store_latent = store_latent try: proc = process_images(p) finally: sd_samplers.store_latent = fun return Processed(p, proc.images, p.seed, \"\")"
  },"/sdwui-docs/dependencies/": {
    "title": "зависимости",
    "keywords": "Getting started",
    "url": "/sdwui-docs/dependencies/",
    "body": "Python 3.10.6 и Git: Windows: загрузите и запустите установщики для Python 3.10.6 (веб-страница, exe или версия win7) и git (веб-страница) Linux (на базе Debian): sudo apt install wget git python3 python3-venv Linux (на базе Red Hat): sudo dnf install wget git python3 Linux (на базе Arch): sudo pacman -S wget git python3 Код из этого репозитория: предпочтительный способ: использование git: git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git. Этот способ упоминается, потому что он позволяет вам обновиться, просто запустив git pull. Эти команды можно использовать из окна командной строки, которое открывается после того, как вы щелкните правой кнопкой мыши в проводнике и выберите «Git Bash здесь». альтернативный способ: используйте опцию «Код» (зеленая кнопка) -&gt; «Скачать ZIP» на главной странице репозитория. Вам все равно нужно установить git, даже если вы выберете это. Для обновления придется заново скачивать zip и заменять файлы. Контрольную точку модели Stable Diffusion, файл с расширением .ckpt, необходимо загрузить и поместить в каталог models/Stable-diffusion. Официальная загрузка Файловое хранилище Torrent (magnet:?xt=urn:btih:3a4a612d75ed088ea542acac52f9f45987488d1c&amp;dn=sd-v1-4.ckpt&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org% 3а1337) Необязательные зависимости ESRGAN (Увеличение масштаба) Модели ESRGAN, такие как модели из базы данных моделей, могут быть помещены в каталог ESRGAN. Файл будет загружен как модель, если он имеет расширение .pth, и он будет отображаться под своим именем в пользовательском интерфейсе. Примечание. Модели RealESRGAN не являются моделями ESRGAN, они несовместимы. Не скачивайте модели RealESRGAN. Не помещайте RealESRGAN в каталог с моделями ESRGAN. Файлы .yaml для моделей SD 2.x 768-v-ema.ckpt config) 512-base-ema.ckpt config 512-depth-ema.ckpt config Загрузите файл конфигурации .yaml и сохраните его в той же папке, что и .ckpt с тем же именем."
  },"/sdwui-docs/developing-custom-scripts/": {
    "title": "Разработка пользовательских скриптов",
    "keywords": "development",
    "url": "/sdwui-docs/developing-custom-scripts/",
    "body": "Установка и использование пользовательских скриптов Определение класса Script можно найти в modules/scripts.py. Чтобы создать свой собственный сценарий, создайте сценарий Python, который реализует класс, и поместите его в папку scripts, используя приведенный ниже пример или другие сценарии, уже находящиеся в папке, в качестве руководства. Класс Script имеет четыре основных метода, более подробно описанных ниже с помощью простого примера сценария, который поворачивает и/или переворачивает сгенерированные изображения. import modules.scripts as scripts import gradio as gr import os from modules import images from modules.processing import process_images, Processed from modules.processing import Processed from modules.shared import opts, cmd_opts, state class Script(scripts.Script): # The title of the script. This is what will be displayed in the dropdown menu.     def title(self):         return \"Flip/Rotate Output\" # Determines when the script should be shown in the dropdown menu via the # returned value. As an example: # is_img2img is True if the current tab is img2img, and False if it is txt2img. # Thus, return is_img2img to only show the script on the img2img tab.     def show(self, is_img2img):         return is_img2img # How the script's is displayed in the UI. See https://gradio.app/docs/#components # for the different UI components you can use and how to create them. # Most UI components can return a value, such as a boolean for a checkbox. # The returned values are passed to the run method as parameters.     def ui(self, is_img2img):         angle = gr.Slider(minimum=0.0, maximum=360.0, step=1, value=0,         label=\"Angle\")         hflip = gr.Checkbox(False, label=\"Horizontal flip\")         vflip = gr.Checkbox(False, label=\"Vertical flip\")         overwrite = gr.Checkbox(False, label=\"Overwrite existing files\")         return [angle, hflip, vflip, overwrite] # This is where the additional processing is implemented. The parameters include # self, the model object \"p\" (a StableDiffusionProcessing class, see # processing.py), and the parameters returned by the ui method. # Custom functions can be defined here, and additional libraries can be imported # to be used in processing. The return value should be a Processed object, which is # what is returned by the process_images method.     def run(self, p, angle, hflip, vflip, overwrite):         # function which takes an image from the Processed object, # and the angle and two booleans indicating horizontal and         # vertical flips from the UI, then returns the         # image rotated and flipped accordingly         def rotate_and_flip(im, angle, hflip, vflip):             from PIL import Image                         raf = im                         if angle != 0:                 raf = raf.rotate(angle, expand=True)             if hflip:                 raf = raf.transpose(Image.FLIP_LEFT_RIGHT)             if vflip:                 raf = raf.transpose(Image.FLIP_TOP_BOTTOM)             return raf         # If overwrite is false, append the rotation information to the filename         # using the \"basename\" parameter and save it in the same directory.         # If overwrite is true, stop the model from saving its outputs and         # save the rotated and flipped images instead.         basename = \"\"         if(not overwrite):             if angle != 0:                 basename += \"rotated_\" + str(angle)             if hflip:                 basename += \"_hflip\"             if vflip:                 basename += \"_vflip\"         else:             p.do_not_save_samples = True         proc = process_images(p)         # rotate and flip each image in the processed images # use the save_images method from images.py to save # them.         for i in range(len(proc.images)):             proc.images[i] = rotate_and_flip(proc.images[i], angle, hflip, vflip)             images.save_image(proc.images[i], p.outpath_samples, basename,             proc.seed + i, proc.prompt, opts.samples_format, info= proc.info, p=p)         return proc"
  },"/sdwui-docs/developing-extensions/": {
    "title": "Разработка расширений",
    "keywords": "development",
    "url": "/sdwui-docs/developing-extensions/",
    "body": "Расширение — это просто подкаталог в каталоге «extensions». Веб-интерфейс взаимодействует с установленными расширениями следующим образом: выполняется скрипт расширения install.py, если он существует. скрипты расширения в каталоге scripts выполняются как обычные пользовательские скрипты, за исключением: sys.path расширен, чтобы включить каталог расширения, поэтому вы можете импортировать в него что угодно, не беспокоясь вы можете использовать scripts.basedir(), чтобы получить текущий каталог расширения (поскольку пользователь может назвать его как угодно) на страницу добавляются файлы javascript расширения в каталоге javascript в настройки добавлены файлы локализации расширения в директории localizations; если есть две локализации с одинаковым названием, они не сливаются, одна заменяет другую. на страницу добавлен файл расширения style.css если расширение имеет файл preload.py в своем корневом каталоге, он загружается до разбора аргументов командной строки если у расширения preload.py есть функция preload, она вызывается, и парсер аргументов командной строки передается ей в качестве аргумента. Вот пример того, как использовать его для добавления аргумента командной строки: def preload(parser): parser.add_argument(\"--wildcards-dir\", type=str, help=\"directory with wildcards\", default=None) О том, как разрабатывать пользовательские сценарии, которые обычно выполняют большую часть работы расширения, см. в разделе Разработка пользовательских сценариев. Расширения локализации Предпочтительный способ локализации проекта — создание расширения. Базовая файловая структура расширения должна быть следующей: 📁 webui root directory ┗━━ 📁 extensions ┗━━ 📁 webui-localization-la_LA &lt;----- name of extension ┗━━ 📁 localizations &lt;----- the single directory inside the extension ┗━━ 📄 la_LA.json &lt;----- actual file with translations Создайте репозиторий github с этой файловой структурой и попросите любого из людей, перечисленных в разделе «Соавторы», добавить ваше расширение в вики. Если вашему языку требуется поддержка javascript/css или даже python, вы также можете добавить это в расширение. install.py install.py — это скрипт, который запускается launch.py, средством запуска, в отдельном процессе перед запуском webui, и он предназначен для установки зависимостей расширения. Он должен находиться в корневом каталоге расширения, а не в каталоге скриптов. Сценарий запускается с переменной среды PYTHONPATH, установленной на путь веб-интерфейса, поэтому вы можете просто импортировать запуск и использовать его функциональность: import launch if not launch.is_installed(\"aitextgen\"): launch.run_pip(\"install aitextgen==0.6.0\", \"requirements for MagicPrompt\")"
  },"/sdwui-docs/extensions/": {
    "title": "Расширения",
    "keywords": "Guides",
    "url": "/sdwui-docs/extensions/",
    "body": "Главная информация Расширения представляют собой более удобную форму пользовательских скриптов. Все расширения существуют в своих собственных подкаталогах внутри каталога extensions. Вы можете использовать git для установки расширения следующим образом: git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients extensions/aesthetic-gradients Это устанавливает расширение из https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients в каталог extensions/aesthetic-gradients. В качестве альтернативы вы можете просто скопировать и вставить каталог в «extensions». Для разработки расширений см. Разработка расширений. Безопасность Поскольку расширения позволяют пользователю устанавливать и запускать произвольный код, это может быть использовано злонамеренно и отключено по умолчанию при работе с параметрами, позволяющими удаленным пользователям подключаться к серверу (--share или --listen). у вас все еще будет пользовательский интерфейс, но попытка установить что-либо приведет к ошибке. Если вы хотите использовать эти параметры и по-прежнему иметь возможность устанавливать расширения, используйте флаг командной строки --enable-insecure-extension-access. Расширения Эстетические градиенты https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-градиенты Создайте вложение из одного или нескольких изображений и используйте его, чтобы применить их стиль к сгенерированным изображениям. Подстановочные знаки https://github.com/AUTOMATIC1111/stable-diffusion-webui-wildcards Позволяет вам использовать синтаксис __name__ в приглашении для получения случайной строки из файла с именем name.txt в каталоге подстановочных знаков. Динамические подсказки https://github.com/adieyal/sd-динамические-подсказки Пользовательское расширение для AUTOMATIC1111/stable-diffusion-webui, которое реализует выразительный язык шаблонов для генерации случайных или комбинаторных подсказок, а также функции для поддержки глубокого каталога подстановочных знаков. структуры. Дополнительные функции и дополнения показаны в readme. Используя это расширение, подсказка: {дом|квартира|домик|коттедж} {летом|зимой|осенью|весной} от {2$$artist1|artist2|artist3} Будут ли какие-либо из следующих подсказок: Летний домик художника1, художника2 Домик осенью от artist3, artist1 Коттедж зимой художник2, художник3 … Это особенно полезно, если вы ищете интересные сочетания исполнителей и стилей. Вы также можете выбрать случайную строку из файла. Предполагая, что у вас есть файл Seasons.txt в WILDCARD_DIR (см. ниже), тогда: __seasons__ приближается Может генерировать следующее: Зима близко Весна идет … Вы также можете использовать один и тот же подстановочный знак дважды. Я люблю __seasons__ больше, чем __seasons__ Я люблю зиму больше, чем лето Я люблю весну больше, чем весну Будка мечты https://github.com/d8ahazard/sd_dreambooth_extension Dreambooth в пользовательском интерфейсе. Требования к настройке и конфигурации см. в файле readme проекта. Включает LoRA (адаптация низкого ранга) На основе репозитория ShivamShiaro. Умный процесс https://github.com/d8ahazard/sd_smartprocess Интеллектуальная обрезка, добавление подписей и улучшение изображений. Браузер изображений https://github.com/yfszzx/stable-diffusion-webui-images-browser Предоставляет интерфейс для просмотра созданных изображений в веб-браузере. Вдохновение https://github.com/yfszzx/stable-diffusion-webui-inspiration Произвольное отображение изображений типичного стиля художника или художественного жанра, после выбора отображается больше изображений этого художника или жанра. Так что вам не нужно беспокоиться о том, как сложно выбрать правильный стиль искусства при создании. Ниже https://github.com/deforum-art/deforum-for-automatic1111-webui Официальный порт Deforum, обширный скрипт для 2D- и 3D-анимации, поддерживающий последовательности ключевых кадров, динамические математические параметры (даже внутри подсказок), динамическое маскирование, оценку глубины и деформацию. Художники для изучения https://github.com/camenduru/stable-diffusion-webui-artists-to-study https://artiststostudy.pages.dev/ адаптировано под расширение для веб-интерфейса. Чтобы установить его, клонируйте репозиторий в каталог «extensions» и перезапустите веб-интерфейс: git clone https://github.com/camenduru/stable-diffusion-webui-artists-to-study Вы можете добавить имя исполнителя в буфер обмена, нажав на него. (спасибо за идею @gmaciocci) Оценщик эстетических изображений https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer Расширение для https://github.com/AUTOMATIC1111/stable-diffusion-webui Вычисляет эстетическую оценку для сгенерированных изображений с помощью предиктора эстетической оценки CLIP+MLP на основе оценщика Чада. -Чад/blob/main/chad_scorer.py) См. Обсуждения. Сохраняет счет в тегах Windows с другими запланированными параметрами Редактор тегов набора данных https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor Японский файл Readme Это расширение для редактирования подписей в обучающем наборе данных для веб-интерфейса Stable Diffusion от AUTOMATIC1111. Он хорошо работает с текстовыми подписями в стиле, разделенном запятыми (например, теги, сгенерированные запросчиком DeepBooru). Подписи в именах файлов изображений могут быть загружены, но отредактированные подписи могут быть сохранены только в виде текстовых файлов. auto-sd-paint-ext https://github.com/Interpause/auto-sd-paint-ext Ранее известный как «auto-sd-krita». Расширение веб-интерфейса AUTOMATIC1111 с плагином Krita (скоро появятся другие студии рисования?) Устаревшая демо Новый пользовательский интерфейс (ВСЕ: демонстрационное изображение) Differences UI no longer freezes during image update Inpainting layer no longer has to be manually hidden, nor use white specifically UI has been improved &amp; squeezed further Scripts API is now possible training-picker https://github.com/Maurdekye/training-picker Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training. Installation Install AUTOMATIC1111’s Stable Diffusion Webui Install ffmpeg for your operating system Clone this repository into the extensions folder inside the webui Drop videos you want to extract cropped frames from into the training-picker/videos folder Unprompted https://github.com/ThereforeGames/unprompted Supercharge your prompt workflow with this powerful scripting language! Unprompted is a highly modular extension for AUTOMATIC1111’s Stable Diffusion Web UI that allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it’s like wildcards on steroids. While the intended usecase is Stable Diffusion, this engine is also flexible enough to serve as an all-purpose text generator. Booru tag autocompletion https://github.com/DominikDoom/a1111-sd-webui-tagcomplete Displays autocompletion hints for tags from “image booru” boards such as Danbooru. Uses local tag CSV files and includes a config for customization. novelai-2-local-prompt https://github.com/animerl/novelai-2-local-prompt Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt. Tokenizer https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer Adds a tab that lets you preview how CLIP model would tokenize your text. Push to 🤗 Hugging Face https://github.com/camenduru/stable-diffusion-webui-huggingface To install it, clone the repo into the extensions directory and restart the web ui: git clone https://github.com/camenduru/stable-diffusion-webui-huggingface pip install huggingface-hub StylePile https://github.com/some9000/StylePile An easy way to mix and match elements to prompts that affect the style of the result. Latent Mirroring https://github.com/dfaker/SD-latent-mirroring Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections Embeddings editor https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor Allows you to manually edit textual inversion embeddings using sliders. seed travel https://github.com/yownas/seed_travel Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds. shift-attention https://github.com/yownas/shift-attention Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second. https://user-images.githubusercontent.com/13150150/193368939-c0a57440-1955-417c-898a-ccd102e207a5.mp4 prompt travel https://github.com/Kahsolt/stable-diffusion-webui-prompt-travel Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space. Sonar https://github.com/Kahsolt/stable-diffusion-webui-sonar Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts. Detection Detailer https://github.com/dustysys/ddetailer An object detection and auto-mask extension for Stable Diffusion web UI. conditioning-highres-fix https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt Randomize https://github.com/stysmmaker/stable-diffusion-webui-randomize Allows for random parameters during txt2img generation. This script is processed for all generations, regardless of the script selected, meaning this script will function with others as well, such as AUTOMATIC1111/stable-diffusion-webui-wildcards. Auto TLS-HTTPS https://github.com/papuSpartan/stable-diffusion-webui-auto-tls-https Allows you to easily, or even completely automatically start using HTTPS. DreamArtist https://github.com/7eu7d7/DreamArtist-sd-webui-extension Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning. WD 1.4 Tagger https://github.com/toriato/stable-diffusion-webui-wd14-tagger Uses a trained model file, produces WD 1.4 Tags. Model link - https://mega.nz/file/ptA2jSSB#G4INKHQG2x2pGAVQBn-yd_U5dMgevGF8YYM9CR_R1SY booru2prompt https://github.com/Malisius/booru2prompt This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD. also see: https://github.com/stysmmaker/stable-diffusion-webui-booru-prompt gelbooru-prompt https://github.com/antis0007/sd-webui-gelbooru-prompt Fetch tags with image hash. Updates planned. Merge Board https://github.com/bbc-mc/sdweb-merge-board Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text. also see: https://github.com/Maurdekye/model-kitchen Depth Maps https://github.com/thygate/stable-diffusion-webui-depthmap-script Creates depthmaps from the generated images. The result can be viewed on 3D or holographic devices like VR headsets or lookingglass display, used in Render or Game- Engines on a plane with a displacement modifier, and maybe even 3D printed. multi-subject-render https://github.com/Extraltodeus/multi-subject-render It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish. depthmap2mask https://github.com/Extraltodeus/depthmap2mask Create masks for img2img based on a depth estimation made by MiDaS. ABG_extension https://github.com/KutsuyaYuki/ABG_extension Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU. Visualize Cross-Attention https://github.com/benkyoujouzu/stable-diffusion-webui-visualize-cross-attention-extension Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info. DAAM https://github.com/kousw/stable-diffusion-webui-daam DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image. Prompt Gallery https://github.com/dr413677671/PromptGallery-stable-diffusion-webui Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers. embedding-inspector https://github.com/tkalayci71/embedding-inspector Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds. Much more intriguing options have since been released, see here. Infinity Grid Generator https://github.com/mcmonkeyprojects/sd-infinity-grid-generator-script Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details. NSFW checker https://github.com/AUTOMATIC1111/stable-diffusion-webui-nsfw-censor Replaces NSFW images with black. Diffusion Defender https://github.com/WildBanjos/DiffusionDefender Prompt blacklist, find and replace, for semi-private and public instances. Config-Presets https://github.com/Zyin055/Config-Presets Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs. Preset Utilities https://github.com/Gerschel/sd_web_ui_preset_utils Preset tool for UI. Planned support for some other custom scripts. DH Patch https://github.com/d8ahazard/sd_auto_fix Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with. Riffusion https://github.com/enlyth/sd-webui-riffusion Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab. Save Intermediate Images https://github.com/AlUlkesh/sd_save_intermediate_images Implements saving intermediate images, with more advanced features. openOutpaint extension https://github.com/zero01101/openOutpaint-webUI-extension A tab with the full openOutpaint UI. Run with the –api flag. Enhanced-img2img https://github.com/OedoSoldier/enhanced-img2img An extension with support for batched and better inpainting."
  },"/sdwui-docs/features/": {
    "title": "Функции",
    "keywords": "Guides",
    "url": "/sdwui-docs/features/",
    "body": "Это страница демонстрации возможностей веб-интерфейса стабильной диффузии. Все примеры не отобраны, если не указано иное. Стабильная диффузия 2.0 Базовые модели Поддерживаются модели: 768-v-ema.ckpt (модель, config) и 512-base-ema.ckpt (модель, config). 2.1 чекпоинты тоже должны работать. скачать чекпоинт (отсюда: https://huggingface.co/stabilityai/stable-diffusion-2) положить в папку models/Stable-Diffusion возьмите конфиг из репозитория SD2.0 и поместите его в то же место, что и контрольная точка, переименовав его, чтобы он имел то же имя файла (т.е. если ваша контрольная точка называется 768-v-ema.ckpt, конфигурация должна называться 768- в-эма.ямл) выберите новую контрольную точку из пользовательского интерфейса Вкладка «Поезд», скорее всего, будет сломана для моделей 2.0. Если 2.0 или 2.1 генерируют черные изображения, включите полную точность с помощью --no-half или попробуйте использовать оптимизацию --xformers. Примечание: SD 2.0 и 2.1 более чувствительны к численной нестабильности FP16 (как отмечено ими самими здесь) из-за их новый модуль перекрестного внимания. На fp16: комментарий для включения в webui-user.bat: @эхо выключено установить ПИТОН= установить GIT = установить VENV_DIR= установите COMMANDLINE_ARGS = ваши параметры командной строки установить STABLE_DIFFUSION_COMMIT_HASH=”c12d960d1ee4f9134c2516862ef991ec52d3f59e” установить ATTN_PRECISION=fp16 позвони в webui.bat Модель с наведением по глубине Подробнее. PR. Инструкции: скачать контрольную точку 512-depth-ema.ckpt поместите его в models/Stable-diffusion возьмите config и поместите его в ту же папку, что и контрольная точка переименовать конфиг в 512-depth-ema.yaml выберите новую контрольную точку из пользовательского интерфейса Модель с глубиной будет работать только на вкладке img2img. Перекрашивание Outpainting расширяет исходное изображение и закрашивает созданное пустое пространство. Пример: Оригинал Окрашивание Снова перекраска Исходное изображение анонимного пользователя с 4chan. Спасибо, анонимный пользователь. Вы можете найти эту функцию на вкладке img2img внизу, в разделе «Сценарий» -&gt; «Перекрашивание бедняка». Outpainting, в отличие от обычной генерации изображения, кажется, очень выигрывает от большого количества шагов. Рецепт хорошей перекраски хорошая подсказка, соответствующая картинке, ползунки для шумоподавления и шкала CFG установлены на максимум, а количество шагов от 50 до 100 с Родовые сэмплеры Euler или DPM2. 81 шаг, Эйлер А 30 шагов, Эйлер А 10 шагов, Эйлер А 80 шагов, Эйлер А Закрашивание На вкладке img2img нарисуйте маску над частью изображения, и эта часть будет закрашена. Варианты покраски: нарисовать маску самостоятельно в веб-редакторе стереть часть картинки во внешнем редакторе и загрузить прозрачную картинку. Любые даже слегка прозрачные участки станут частью маски. Имейте в виду, что некоторые редакторы по умолчанию сохраняют полностью прозрачные области черными. изменить режим (в правом нижнем углу картинки) на “Загрузить маску” и выбрать для маски отдельное черно-белое изображение (white=inpaint). Покраска модели RunwayML обучил дополнительную модель, специально предназначенную для раскрашивания. Эта модель принимает дополнительные входные данные — исходное изображение без шума плюс маска — и, кажется, работает намного лучше. Скачать и дополнительную информацию для модели можно здесь: https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion. Чтобы использовать модель, вы должны переименовать контрольную точку так, чтобы ее имя файла заканчивалось на inpainting.ckpt, например, 1.5-inpainting.ckpt. После этого просто выберите контрольную точку, как вы обычно выбираете любую контрольную точку, и все готово. Маскированный контент Поле маскированного содержимого определяет, что содержимое помещается в маскированные области до того, как они будут закрашены. маска заполнить оригинальный скрытый шум скрытое ничего Inpaint в полном разрешении Обычно inpainting изменяет размер изображения до целевого разрешения, указанного в пользовательском интерфейсе. С Inpaint в полном разрешении включена, изменяется размер только маскируемой области, и после обработки она вставляется обратно в исходное изображение. Это позволяет работать с большими изображениями и позволяет визуализировать закрашенный объект с гораздо большим разрешением. Вход Раскрасить нормальный Inpaint в полном разрешении Маскирующий режим Существует два варианта маскированного режима: Inpaint masked - закрашивается область под маской Inpaint not masked - под маской без изменений, все остальное закрашивается Альфа-маска Вход Выход Матрица подсказок Разделите несколько подсказок с помощью символа |, и система создаст изображение для каждой их комбинации. Например, если вы используете подсказку «оживленная городская улица в современном городе|иллюстрация|кинематографическое освещение», возможны четыре комбинации (первая часть подсказки всегда сохраняется): оживленная городская улица в современном городе оживленная городская улица в современном городе, иллюстрация оживленная городская улица в современном городе, кинематографическое освещение оживленная городская улица в современном городе, иллюстрация, кинематографическое освещение В этом порядке будут созданы четыре изображения, все с одним и тем же начальным числом и каждое с соответствующей подсказкой: Другой пример, на этот раз с 5 подсказками и 16 вариантами: Вы можете найти эту функцию внизу, в разделе «Сценарий» -&gt; «Матрица подсказок». Цветной эскиз Базовый инструмент для раскрашивания img2img. Чтобы использовать эту функцию в img2img, включите ее с помощью --gradio-img2img-tool color-sketch в аргументах командной строки. Чтобы использовать эту функцию в режиме рисования, включите ее с помощью --gradio-inpaint-tool color-sketch. Браузеры на основе Chromium поддерживают инструмент-дроппер. (см. рисунок) Стабильный диффузионный апскейл Масштабируйте изображение с помощью RealESRGAN/ESRGAN, а затем просматривайте фрагменты результата, улучшая их с помощью img2img. У него также есть возможность позволить вам самостоятельно выполнять масштабирование во внешней программе и просто просматривать плитки с помощью img2img. Оригинальная идея: https://github.com/jquesnelle/txt2imghd. Это независимая реализация. Чтобы использовать эту функцию, выберите «Увеличение SD в раскрывающемся списке сценариев» (вкладка img2img). Входное изображение будет увеличено в два раза по сравнению с оригиналом. ширина и высота, а ползунки ширины и высоты пользовательского интерфейса определяют размер отдельных плиток. Из-за перекрытия, размер тайла может быть очень важен: для изображения 512x512 требуется девять тайлов 512x512 (из-за перекрытия), но только четыре тайла 640x640. Рекомендуемые параметры для апскейлинга: Метод выборки: Эйлер a Сила шумоподавления: 0,2, может быть увеличена до 0,4, если вы любите приключения. Оригинал РеалЕСРГАН топаз гигапиксель SD высококлассный Внимание/акцент Использование () в подсказке увеличивает внимание модели к заключенным в него словам, а [] уменьшает его. Вы можете комбинировать несколько модификаторов: Шпаргалка: a (слово) - увеличить внимание к слову в 1,1 раза a ((слово)) - увеличить внимание к слову в 1,21 раза (= 1,1 * 1,1) a [слово] - уменьшить внимание к слову в 1,1 раза a (word:1.5) - увеличить внимание к слову в 1,5 раза a (word:0.25) - уменьшить внимание к слову в 4 раза (= 1 / 0,25) a \\(word\\) - использовать литеральные символы () в подсказке С помощью () вес может быть указан следующим образом: (text:1.4). Если вес не указан, предполагается, что он равен 1,1. Указание веса работает только с (), но не с []. Если вы хотите использовать какие-либо буквальные символы ()[] в подсказке, используйте обратную косую черту, чтобы избежать их: anime_\\(character\\). 29 сентября 2022 г. была добавлена ​​новая реализация, поддерживающая escape-символы и числовые веса. Недостатком новой реализации является то, что старая не была идеальной и иногда съедала символы: «a (((farm))), daytime», например, без запятой превращалось в «farm daytime». Это поведение не поддерживается новой реализацией, которая корректно сохраняет весь текст, и это означает, что ваши сохраненные начальные значения могут создавать разные изображения. На данный момент в настройках есть возможность использовать старую реализацию. NAI использует мою реализацию до 2022-09-29, за исключением того, что они имеют 1,05 в качестве множителя и используют {} вместо (). Таким образом, преобразование применяется: их {word} = наше (word:1.05) их `` = наше (word:1.1025) их [слово] = наше (слово:0,952) (0,952 = 1/1,05) их [[слово]] = наше (слово:0,907) (0,907 = 1/1,05/1,05) петля Выбор сценария обратной связи в img2img позволяет автоматически передавать выходное изображение в качестве входных данных для следующего пакета. Эквивалентно сохранение выходного изображения и замена им входного изображения. Параметр количества пакетов определяет, сколько итераций это вы получаете. Обычно при этом вы сами выбираете одно из многих изображений для следующей итерации, поэтому полезность этой функции может быть сомнительным, но мне удалось получить с ее помощью несколько очень хороших результатов, которые я не смог получить иначе. Пример: (выбранный результат) Исходное изображение анонимного пользователя с 4chan. Спасибо, анонимный пользователь. График X/Y Создает сетку изображений с различными параметрами. Выберите, какие параметры должны быть общими для строк и столбцов, используя Поля типа X и типа Y и введите эти параметры, разделенные запятой, в поля значений X/Y. Для целого числа поддерживаются числа с плавающей запятой и диапазоны. Примеры: Простые диапазоны: 1-5 = 1, 2, 3, 4, 5 Диапазоны с приращением в скобках: 1-5 (+2) = 1, 3, 5 10-5 (-3) = 10, 7 1-3 (+0,5) = 1, 1,5, 2, 2,5, 3 Диапазоны с количеством в квадратных скобках: 1-10 [5] = 1, 3, 5, 7, 10 0,0-1,0 [6] = 0,0, 0,2, 0,4, 0,6, 0,8, 1,0 Вот настройки, которые создают график выше: Подсказка S/R Подсказка S/R — один из наиболее сложных для понимания режимов работы графика X/Y. S/R означает поиск/замену, и вот что он делает — вы вводите список слов или фраз, он берет первое из списка и обрабатывает его как ключевое слово и заменяет все экземпляры этого ключевого слова другими элементами из списка. . Например, с подсказкой «человек держит яблоко, 8к чистый» и подсказкой S/R «яблоко, арбуз, пистолет» вы получите три подсказки: человек с яблоком, 8к чистый человек, держащий арбуз, чистый 8k человек с пистолетом, чистый 8к Список использует тот же синтаксис, что и строка в файле CSV, поэтому, если вы хотите включить запятые в свои записи, вы должны поместить текст в кавычки и убедиться, что между кавычками и разделяющими запятыми нет пробела: тьма, свет, зелень, тепло - 4 предмета - тьма, свет, зелень, тепло тьма, \"свет, зелень\", тепло - НЕПРАВИЛЬНО - 4 пункта - тьма, ``свет, зелень, тепло` “тьма”, “свет, зелень”, тепло - ПРАВИЛЬНО - 3 пункта - темнота, свет, зелень, тепло` Текстовая инверсия Краткое пояснение: поместите свои вложения в каталог «embeddings» и используйте имя файла в подсказке. Длинное объяснение: текстовая инверсия Изменение размера Есть три варианта изменения размера входных изображений в режиме img2img: Just resize - просто изменяет размер исходного изображения до целевого разрешения, что приводит к неправильному соотношению сторон. Обрезка и изменение размера - изменение размера исходного изображения с сохранением соотношения сторон, чтобы оно занимало все целевое разрешение, и обрезка выступающих частей. Изменение размера и заполнение - изменение размера исходного изображения с сохранением соотношения сторон, чтобы оно полностью соответствовало целевому разрешению, и заполнение пустого пространства строками/столбцами из исходного изображения. Пример: Выбор метода выборки Выберите один из нескольких методов выборки для txt2img: Изменение размера семени Эта функция позволяет создавать изображения из известных семян с разным разрешением. Обычно при изменении разрешения изображение полностью изменится, даже если вы сохраните все остальные параметры, включая начальное значение. При изменении размера семени вы указываете разрешение исходного изображения, и модель, скорее всего, создаст что-то очень похожее на него, даже в другом разрешении. В приведенном ниже примере крайняя левая картинка имеет размер 512x512, а остальные создаются с точно такими же параметрами, но с большей вертикалью. разрешающая способность. Информация Изображение Изменение размера семени не включено Семя изменено с 512x512 Родовые семплеры в этом немного хуже остальных. Вы можете найти эту функцию, установив флажок «Дополнительно» рядом с семенем. Вариации Ползунок «Сила вариации» и поле «Исходное значение вариации» позволяют указать, насколько нужно изменить существующее изображение, чтобы оно выглядело вроде другой. На максимальной силе вы получите картинки с Вариационным сидом, на минимальной - картинки с исходным Сидом (кроме при использовании наследственных семплеров). Вы можете найти эту функцию, установив флажок «Дополнительно» рядом с семенем. Стили Нажмите кнопку «Сохранить подсказку как стиль», чтобы записать текущую подсказку в файл styles.csv с набором стилей. Dropbox для справа от приглашения вы сможете выбрать любой стиль из ранее сохраненных и автоматически добавить его к вашему вводу. Чтобы удалить стиль, вручную удалите его из styles.csv и перезапустите программу. если вы используете специальную строку {prompt} в своем стиле, она заменит все, что в данный момент находится в приглашении, на эту позицию, а не добавит стиль к вашему приглашению. Отрицательное приглашение Позволяет вам использовать другую подсказку о том, чего модель должна избегать при создании изображения. Это работает с помощью отрицательное приглашение для безусловного кондиционирования в процессе выборки вместо пустой строки. Расширенное объяснение: Отрицательная подсказка Оригинал Негатив: фиолетовый Отрицательное: щупальца Опросчик CLIP Автор: https://github.com/pharmapsychotic/clip-interrogator Опросчик CLIP позволяет извлекать подсказку из изображения. Подсказка не позволит вам воспроизвести это точное изображение (иногда оно даже не будет близко), но это может быть хорошим началом. При первом запуске опросчика CLIP будет загружено несколько гигабайт моделей. Опросчик CLIP состоит из двух частей: одна представляет собой модель BLIP, которая создает текстовое описание из изображения. Другая — это модель CLIP, которая выбирает из списка несколько строк, относящихся к изображению. По умолчанию там всего один список - список художников (из artists.csv). Вы можете добавить больше списков, выполнив следующие действия: создайте каталог опросить в том же месте, что и webui поместите в него текстовые файлы с соответствующим описанием в каждой строке Например, какие текстовые файлы использовать, см. https://github.com/pharmapsychotic/clip-interrogator/tree/main/data. На самом деле, вы можете просто взять оттуда файлы и использовать их — просто пропустите artist.txt, потому что у вас уже есть список художников в artists.csv (или используйте его тоже, кто вас остановит). Каждый файл добавляет одну строку текста к окончательному описанию. Если вы добавите “.top3.” к имени файла, например, flavors.top3.txt, три наиболее релевантные строки из этого файла будут добавлено в подсказку (другие номера тоже работают). Существуют настройки, относящиеся к этой функции: Опросить: хранить модели в VRAM - не выгружать модели Опроса из памяти после их использования. Для пользователей с большим количеством видеопамяти. Опрашивать: использовать художников из artists.csv - добавляет исполнителя из artists.csv при опросе. Может быть полезно отключить, когда у вас есть список исполнителей в каталоге «допросить». Опросить: количество лучей для BLIP - параметр, влияющий на то, насколько подробны описания из модели BLIP (первая часть сгенерированного приглашения) Опросить: минимальная длина описания - минимальная длина текста модели BLIP Опросить: максимальная длина описания - максимальная длина текста модели BLIP Опросить: максимальное количество строк в текстовом файле - опросчик будет рассматривать только это количество первых строк в файле. Если установлено значение 0, значение по умолчанию равно 1500, то есть примерно столько, сколько может выдержать видеокарта на 4 ГБ. Быстрое редактирование Быстрое редактирование позволяет вам начать выборку одного изображения, но в середине переключиться на что-то другое. Базовый синтаксис для этого: [from:to:when] Где «от» и «до» — это произвольные тексты, а «когда» — это число, определяющее, на каком конце цикла выборки должно быть выполнено переключение. Чем позже, тем меньше мощности у модели для рисования текста «в» вместо текста «из». Если когда является числом от 0 до 1, это часть количества шагов, после которых нужно сделать переключение. Если это целое число больше нуля, это всего лишь шаг, после которого нужно сделать переключение. Вложение одной подсказки в другую действительно работает. Кроме того: [to:when] - добавляет to в подсказку после фиксированного количества шагов (when) [from::when] - удаляет from из подсказки после фиксированного количества шагов (when) Пример: пейзаж [фэнтези:киберпанк:16] В начале модель будет рисовать “фантазийный пейзаж”. После шага 16 он переключится на рисование «киберпанк-пейзажа», продолжая с того места, где остановился, с фантазией. Вот более сложный пример с несколькими правками: фантастический пейзаж с [горой:озером:0,25] и [дубом:елкой:0,75][на переднем плане::0,6][на заднем плане:0,25] [дрянной:мастерский:0,5] ​​(сэмплер имеет 100 шагов) в начале фантастический пейзаж с горой и дубом на переднем плане дрянной после шага 25, фантастический пейзаж с озером и дубом на переднем плане, на заднем плане дрянной после шага 50 фантастический пейзаж с озером и дубом на переднем плане на заднем плане мастерски после шага 60, фантастический пейзаж с озером и дубом на заднем плане мастерски после шага 75, фантастический пейзаж с озером и рождественской елкой на заднем плане мастерски Картинка вверху была сделана с подсказкой: `Официальный портрет улыбающегося генерала Второй мировой войны, [мужчина:женщина:0,99], веселое, счастливое, детально проработанное лицо, 20 век, высокая детализация, кинематографическое освещение, цифровая художественная картина Грега Рутковски И число 0,99 заменяется тем, что вы видите в метках столбцов на изображении. Последний столбец на картинке — [мужчина:женщина:0.0], что, по сути, означает, что вы просите модель нарисовать женщину с самого начала, не начиная с генерала-мужчины, и поэтому она выглядит так не похоже на другие. Чередующиеся слова Удобный синтаксис для замены каждого шага. [корова лошадь] в поле На шаге 1 подсказка «корова в поле». Шаг 2 — «лошадь в поле». Шаг 3 — «корова в поле» и так далее. См. более сложный пример ниже. На шаге 8 цепочка возвращается от «мужчина» к «корове». [корова корова лошадь человек амурский тигр бык человек] в поле Редактирование подсказок было впервые реализовано Doggettx в этот пост на myspace.com. Высокое разрешение. исправить Удобный вариант для частичного рендеринга изображения с более низким разрешением, увеличения его масштаба, а затем добавления деталей с высоким разрешением. По умолчанию txt2img делает ужасные картинки в очень высоком разрешении, что позволяет избежать использования композиции маленькой картинки. Включается установкой флажка «Highres. fix» на странице txt2img. Без С Составная диффузия Метод, позволяющий комбинировать несколько подсказок. объединяйте подсказки, используя заглавную букву И кошка И собака Поддерживает веса для подсказок: «кошка: 1,2 И собака И пингвин: 2,2» Значение веса по умолчанию равно 1. Это может быть очень полезно для объединения нескольких вложений в ваш результат: creature_embedding in the forest:0.7 AND arcane_embedding:0.5 AND glitch_embedding:0.2 Использование значения ниже 0,1 практически не даст эффекта. a cat AND a dog:0.03 даст в основном тот же результат, что и cat Это может быть удобно для создания точно настроенных рекурсивных вариантов, продолжая добавлять дополнительные подсказки к вашей сумме. creature_embedding на бревне И лягушка: 0,13 И желтые глаза: 0,08 Прерывать Нажмите кнопку «Прерывание», чтобы остановить текущую обработку. Поддержка видеокарты 4GB Оптимизация для графических процессоров с низким объемом видеопамяти. Это должно позволить генерировать изображения 512x512 на видеокартах с 4 Гб памяти. --lowvram — это повторная реализация идеи оптимизации basujindal. Модель разделена на модули, и в памяти GPU хранится только один модуль; когда необходимо запустить другой модуль, предыдущий удаляется из памяти GPU. Природа этой оптимизации замедляет обработку — примерно в 10 раз медленнее. по сравнению с нормальной работой на моей RTX 3090. --medvram — это еще одна оптимизация, которая должна значительно сократить использование видеопамяти, не обрабатывая условные и безусловное шумоподавление в том же пакете. Эта реализация оптимизации не требует каких-либо модификаций исходного кода Stable Diffusion. Реставрация лица Позволяет улучшать лица на изображениях с помощью GFPGAN или CodeFormer. На каждой вкладке есть флажок, чтобы использовать восстановление лица, а также отдельная вкладка, которая просто позволяет вам использовать восстановление лица на любом изображении, с ползунком, который контролирует, насколько видимым эффект есть. Вы можете выбрать один из двух методов в настройках. Оригинал ГФГАН КодФормер Сохранение Нажмите кнопку «Сохранить» в разделе вывода, и сгенерированные изображения будут сохранены в каталоге, указанном в настройках; параметры генерации будут добавлены в файл csv в том же каталоге. Загрузка Графика загрузки Gradio очень негативно влияет на скорость обработки нейросети. Моя RTX 3090 делает изображения примерно на 10% быстрее, когда вкладка с градиентом не активна. По умолчанию интерфейс теперь скрывает анимацию процесса загрузки и заменяет ее статическим текстом «Загрузка…», что позволяет тот же эффект. Используйте параметр командной строки --no-progressbar-hiding, чтобы отменить это и показать анимацию загрузки. Оперативная проверка Stable Diffusion имеет ограничение на длину вводимого текста. Если ваше приглашение слишком длинное, вы получите предупреждение в поле вывода текста, показывающее, какие части вашего текста были усечены и проигнорированы моделью. Информация о PNG Добавляет информацию о параметрах генерации в PNG в виде текстового фрагмента. Ты можно просмотреть эту информацию позже с помощью любого программного обеспечения, которое поддерживает просмотр Информация о фрагменте PNG, например: https://www.nayuki.io/page/png-file-chunk-inspector Настройки Вкладка с настройками, позволяет использовать UI для редактирования более половины параметров, которые ранее были командной строкой. Настройки сохраняются в файл config.js. Настройки, которые остаются в командной строке параметры - это те, которые требуются при запуске. Формат имен файлов Поле «Шаблон имени файла изображения» на вкладке «Настройки» позволяет настроить имена файлов сгенерированных изображений txt2img и img2img. Этот шаблон определяет параметры генерации, которые вы хотите включить в имена файлов, и их порядок. Поддерживаемые теги: [шаги], [cfg], [приглашение], [prompt_no_styles], [prompt_spaces], [ширина], [высота], [стили], [сэмплер], [seed], [model_hash], [prompt_words], [ дата], [дата-время], [job_timestamp]. Однако этот список будет пополняться новыми дополнениями. Вы можете получить актуальный список поддерживаемых тегов, наведя указатель мыши на метку «Шаблон имени файла изображений» в пользовательском интерфейсе. Пример шаблона: [seed]-[steps]-[cfg]-[sampler]-[prompt_spaces] Примечание о тегах «подсказки»: «[подсказка]» добавит символы подчеркивания между словами подсказки, в то время как «[prompt_spaces]» сохранит подсказку без изменений (проще снова скопировать/вставить в пользовательский интерфейс). [prompt_words] — это упрощенная и очищенная версия вашей подсказки, которая уже использовалась для создания имен подкаталогов, только со словами вашей подсказки (без пунктуации). Если вы оставите это поле пустым, будет применен шаблон по умолчанию ([seed]-[prompt_spaces]). Обратите внимание, что теги фактически заменяются внутри шаблона. Это означает, что вы также можете добавить к этому шаблону слова, не являющиеся тегами, чтобы сделать имена файлов еще более явными. Например: s=[seed],p=[prompt_spaces] Пользовательские скрипты Если программа запущена с параметром --allow-code, появится дополнительное поле ввода текста для кода скрипта. доступен внизу страницы в разделе Скрипты -&gt; Пользовательский код. Это позволяет вам вводить python код, который будет работать с изображением. В коде доступ к параметрам из веб-интерфейса с помощью переменной p и предоставление выходных данных для веб-интерфейса. с помощью функции display(images, seed, info). Также доступны все глобалы из скрипта. Простой скрипт, который просто обработает изображение и выведет его в обычном режиме: import modules.processing processed = modules.processing.process_images(p) print(\"Seed was: \" + str(processed.seed)) display(processed.images, processed.seed, processed.info) Конфигурация пользовательского интерфейса Вы можете изменить параметры элементов пользовательского интерфейса: группы радио: выбор по умолчанию ползунки: значение по умолчанию, мин., макс., шаг флажки: отмеченное состояние ввод текста и чисел: значения по умолчанию Файл ui-config.json находится в каталоге webui, и он создается автоматически, если у вас его нет при запуске программы. Флажки, которые обычно расширяют скрытый раздел, изначально не будут этого делать, если они установлены в качестве записей конфигурации пользовательского интерфейса. Некоторые настройки нарушат обработку, например, шаг, не кратный 64 для ширины и высоты, а некоторые, например, изменение значения по умолчанию. на вкладке img2img, может нарушить пользовательский интерфейс. У меня нет планов обращаться к ним в ближайшем будущем. #ЕСРГАН Возможно использование моделей ESRGAN на вкладке «Дополнительно», а также в апскейле SD. Чтобы использовать модели ESRGAN, поместите их в каталог ESRGAN в том же месте, что и webui.py. Файл будет загружен как модель, если он имеет расширение .pth. Возьмите модели из базы данных моделей. Поддерживаются не все модели из базы данных. Все модели 2x, скорее всего, не поддерживаются. альтернативный тест img2img Деконструирует входное изображение, используя обратный диффузор Эйлера, чтобы создать шаблон шума, используемый для создания входной подсказки. В качестве примера можно использовать это изображение. Выберите альтернативный тест img2img в разделе scripts. Настройте параметры процесса реконструкции: Используйте краткое описание сцены: «Улыбающаяся женщина с каштановыми волосами». Описание функций, которые вы хотите изменить, помогает. Установите это как стартовую подсказку и «Исходную подсказку ввода» в настройках скрипта. Вы ДОЛЖНЫ использовать метод выборки Эйлера, так как этот скрипт построен на нем. Шаги выборки: 50-60. Это НАМНОГО совпадает со значением шагов декодирования в сценарии, иначе у вас будут плохие времена. Используйте 50 для этой демонстрации. Шкала CFG: 2 или ниже. Для этой демонстрации используйте 1.8. (Подсказка: вы можете отредактировать ui-config.json, чтобы изменить «img2img/CFG Scale/step» на .1 вместо .5. Сила шумоподавления - это имеет значение, вопреки тому, что говорилось в старых документах. Установите его на 1. Ширина/Высота - Используйте ширину/высоту входного изображения. Сид… можешь не обращать на это внимания. Обратный Эйлер теперь генерирует шум для изображения. Масштаб декодирования cfg - где-то ниже 1 - самое приятное место. Для демонстрации используйте 1. Шаги декодирования - как упоминалось выше, это должно соответствовать вашим шагам выборки. 50 для демонстрации, рассмотрите возможность увеличения до 60 для более подробных изображений. После того, как все вышеперечисленное будет выполнено, вы сможете нажать «Создать» и получить результат, очень близкий к оригиналу. Убедившись, что сценарий повторно создает исходную фотографию с хорошей степенью точности, вы можете попробовать изменить детали подсказки. Более крупные вариации оригинала, скорее всего, приведут к тому, что изображение будет иметь совершенно другую композицию, чем исходное изображение. Пример вывода с использованием указанных выше настроек и приведенных ниже подсказок (рыжие волосы/пони не показаны) «Улыбающаяся женщина с голубыми волосами». Работает. «Хмурая женщина с каштановыми волосами». Работает. «Хмурая женщина с рыжими волосами». Работает. «Нахмуренная женщина с рыжими волосами верхом на лошади». Кажется, мы полностью заменили женщину, и теперь у нас есть рыжая пони. пользователь.css Создайте файл с именем user.css рядом с webui.py и поместите в него собственный код CSS. Например, это делает галерею выше: #txt2img_gallery, #img2img_gallery{ min-height: 768px; } Полезный совет: вы можете добавить /?__theme=dark к URL-адресу веб-интерфейса, чтобы включить встроенную * темную тему *. напр. (http://127.0.0.1:7860/?__theme=темный) Кроме того, вы можете добавить --theme=dark к set COMMANDLINE_ARGS= в webui-user.bat например установить COMMANDLINE_ARGS=--theme=темный уведомление.mp3 Если в корневой папке webui присутствует аудиофайл с именем notification.mp3, он будет воспроизведен после завершения процесса генерации. Как источник вдохновения: https://pixabay.com/sound-effects/search/ding/?duration=0-30 https://pixabay.com/sound-effects/search/notification/?duration=0-30 Твики Игнорировать последние слои модели CLIP Это ползунок в настройках, и он определяет, насколько рано должна быть остановлена ​​обработка подсказки сетью CLIP. Более подробное объяснение: CLIP — это очень продвинутая нейронная сеть, которая преобразует ваш текст подсказок в числовое представление. Нейронные сети очень хорошо работают с этим числовым представлением, поэтому разработчики SD выбрали CLIP в качестве одной из 3 моделей, используемых в методе стабильной диффузии для создания изображений. Поскольку CLIP — это нейронная сеть, это означает, что в ней много слоев. Ваша подсказка оцифровывается простым способом, а затем передается через слои. Вы получаете числовое представление приглашения после 1-го уровня, вы передаете его во второй уровень, вы передаете результат этого в третий и т. д., пока не дойдете до последнего уровня, и это вывод CLIP, который используется в стабильной версии. диффузия. Это значение ползунка равное 1. Но вы можете остановиться раньше и использовать вывод предпоследнего слоя — это значение ползунка равное 2. Чем раньше вы остановитесь, тем меньше слоев нейронной сети обработает подсказку. Некоторые модели были обучены с такой настройкой, поэтому установка этого значения помогает добиться лучших результатов на этих моделях."
  },"/sdwui-docs/install-on-amd/": {
    "title": "установить на амд",
    "keywords": "development",
    "url": "/sdwui-docs/install-on-amd/",
    "body": "Инструкции ниже работают только в Linux! Альтернативное руководство для пользователя Windows можно найти здесь (непроверено). Работает изначально Выполните следующее: git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui cd stable-diffusion-webui python -m venv venv source venv/bin/activate python -m pip install --upgrade pip wheel # It's possible that you don't need \"--precision full\", dropping \"--no-half\" however crashes my drivers TORCH_COMMAND='pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/rocm5.1.1' python launch.py --precision full --no-half В следующих прогонах вам нужно будет выполнить только: cd stable-diffusion-webui # Optional: \"git pull\" to update the repository source venv/bin/activate # It's possible that you don't need \"--precision full\", dropping \"--no-half\" however crashes my drivers TORCH_COMMAND='pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/rocm5.1.1' python launch.py --precision full --no-half Первое поколение после запуска WebUI может занять очень много времени, и вы можете увидеть сообщение, похожее на это: MIOpen(HIP): Предупреждение [SQLiteBase] Отсутствует файл системной базы данных: gfx1030_40.kdb Производительность может ухудшиться. Пожалуйста, следуйте инструкции по установке: https://github.com/ROCmSoftwarePlatform/MIOpen#installing-miopen-kernels-package Следующие поколения должны работать с регулярной производительностью. Вы можете перейти по ссылке в сообщении, и если вдруг чтобы использовать ту же операционную систему, выполните описанные здесь действия, чтобы устранить эту проблему. Если нет четкого способа компиляции или установите ядра MIOpen для вашей операционной системы, рассмотрите возможность следования приведенному ниже руководству «Запуск внутри Docker». Запуск внутри Docker Извлеките последний образ Docker rocm/pytorch, запустите образ и прикрепите его к контейнеру (взято из rocm/pytorch документация): docker run -it --network=host --device=/dev/kfd --device=/dev/dri --group-add=video --ipc=host --cap-add=SYS_PTRACE --security-opt seccomp=unconfined -v $HOME/dockerx:/dockerx rocm/pytorch Выполните следующее внутри контейнера: cd /dockerx git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui cd stable-diffusion-webui python -m venv venv source venv/bin/activate python -m pip install --upgrade pip wheel # It's possible that you don't need \"--precision full\", dropping \"--no-half\" however crashes my drivers TORCH_COMMAND='pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/rocm5.1.1' REQS_FILE='requirements.txt' python launch.py --precision full --no-half Следующие запуски потребуют от вас только перезапустить контейнер, снова подключиться к нему и выполнить следующее внутри container: найдите имя контейнера в этом списке: docker container ls --all, выберите тот, который соответствует rocm/pytorch, перезапустите его: docker container restart &lt;container-id&gt;, затем подключитесь к нему: `docker exec -it bash`. ```bash cd /dockerx/stable-diffusion-webui # Optional: \"git pull\" to update the repository source venv/bin/activate # It's possible that you don't need \"--precision full\", dropping \"--no-half\" however crashes my drivers TORCH_COMMAND='pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/rocm5.1.1' REQS_FILE='requirements.txt' python launch.py --precision full --no-half ``` Папка `/dockerx` внутри контейнера должна быть доступна в вашем домашнем каталоге под тем же именем. ## Обновление версии Python внутри Docker Если веб-интерфейс становится несовместимым с предустановленной версией Python 3.7 внутри образа Docker, вот инструкции по его обновлению (при условии, что вы успешно выполнили «Запуск внутри Docker»): Выполните следующее внутри контейнера: ```bash apt install python3.9-full # Confirm every prompt update-alternatives --install /usr/local/bin/python python /usr/bin/python3.9 1 echo 'PATH=/usr/local/bin:$PATH' &gt;&gt; ~/.bashrc ``` Затем перезапустите контейнер и снова подключитесь. Если вы проверите `python --version`, теперь должно быть написано `Python 3.9.5` или новее. Запустите rm -rf /dockerx/stable-diffusion-webui/venv внутри контейнера, а затем следуйте инструкциям в разделе «Запуск внутри Docker», пропуская «git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui» и используя модифицированный вместо этого запустите команду ниже: ```bash TORCH_COMMAND='pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/rocm5.1.1' python launch.py --precision full --no-half ``` Возможно, вам не нужно \"--precision full\", убрав \"--no-half\", однако это может не сработать для всех. Некоторые карты, такие как Radeon RX 6000 Series и RX 500 Series, будут нормально работать без опции `--precision full --no-half`, что сэкономит много оперативной памяти. (отмечено [здесь](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/5468).) С этого момента всегда используйте эту новую команду запуска, а также при перезапуске веб-интерфейса в следующих запусках."
  },"/sdwui-docs/install-on-nvidia/": {
    "title": "установить на нвидиа",
    "keywords": "development",
    "url": "/sdwui-docs/install-on-nvidia/",
    "body": "Перед попыткой установки убедитесь, что все необходимые зависимости соблюдены. Автоматическая установка Окна Запустите webui-user.bat из проводника Windows как обычно, не администратор, пользователь. См. раздел Устранение неполадок, чтобы узнать, что делать, если что-то пойдет не так. Линукс Чтобы установить в каталог по умолчанию /home/$(whoami)/stable-diffusion-webui/, запустите: bash &lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh) Чтобы настроить установку, клонируйте репозиторий в нужное место, измените необходимые переменные в webui-user.sh и запустите: bash webui.sh Почти автоматическая установка и запуск Чтобы установить необходимые пакеты через pip без создания виртуальной среды, запустите: python launch.py Аргументы командной строки могут быть переданы напрямую, например: python launch.py --opt-split-attention --ckpt ../secret/anime9999.ckpt Ручная установка Ручная установка очень устарела и, вероятно, не будет работать. проверьте colab в файле readme репо для получения инструкций. Следующий процесс устанавливает все вручную как в Windows, так и в Linux (последний требует замены dir на ls): # install torch with CUDA support. See https://pytorch.org/get-started/locally/ for more instructions if this fails. pip install torch --extra-index-url https://download.pytorch.org/whl/cu113 # check if torch supports GPU; this must output \"True\". You need CUDA 11. installed for this. You might be able to use # a different version, but this is what I tested. python -c \"import torch; print(torch.cuda.is_available())\" # clone web ui and go into its directory git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui # clone repositories for Stable Diffusion and (optionally) CodeFormer mkdir repositories git clone https://github.com/CompVis/stable-diffusion.git repositories/stable-diffusion git clone https://github.com/CompVis/taming-transformers.git repositories/taming-transformers git clone https://github.com/sczhou/CodeFormer.git repositories/CodeFormer git clone https://github.com/salesforce/BLIP.git repositories/BLIP # install requirements of Stable Diffusion pip install transformers==4.19.2 diffusers invisible-watermark --prefer-binary # install k-diffusion pip install git+https://github.com/crowsonkb/k-diffusion.git --prefer-binary # (optional) install GFPGAN (face restoration) pip install git+https://github.com/TencentARC/GFPGAN.git --prefer-binary # (optional) install requirements for CodeFormer (face restoration) pip install -r repositories/CodeFormer/requirements.txt --prefer-binary # install requirements of web ui pip install -r requirements.txt --prefer-binary # update numpy to latest version pip install -U numpy --prefer-binary # (outside of command line) put stable diffusion model into web ui directory # the command below must output something like: 1 File(s) 4,265,380,512 bytes dir model.ckpt Установка завершена, чтобы запустить веб-интерфейс, выполните: python webui.py Инструкции по WSL2 для Windows 11 Чтобы установить в дистрибутиве Linux в Windows 11 WSL2: # install conda (if not already done) wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh chmod +x Anaconda3-2022.05-Linux-x86_64.sh ./Anaconda3-2022.05-Linux-x86_64.sh # Clone webui repo git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui # Create and activate conda env conda env create -f environment-wsl2.yaml conda activate automatic На этом этапе можно применить инструкции по установке вручную, начиная с шага «# клонировать репозитории для Stable Diffusion и (необязательно) CodeFormer». Альтернативная установка в Windows с помощью Conda Предпосылки *(Только если у вас их нет)*. Предполагается, что Chocolatey установлен. # установить гит шоколад установить git # установить конду шоколад установить anaconda3 Необязательные параметры: git, conda Установить (предупреждение: размер некоторых файлов превышает несколько гигабайт, сначала убедитесь, что у вас есть место) Загрузите как .zip и распакуйте или используйте git для клонирования. клон git https://github.com/AUTOMATIC1111/stable-diffusion-webui.git Запустите приглашение Anaconda. Следует отметить, что вы можете использовать более старые версии Python, но вам может потребоваться вручную удалить такие функции, как оптимизация кеша, что снизит вашу производительность. ``` ударить Перейдите в каталог git cd “GIT\\StableDiffusion” Создать среду conda create -n StableDiffusion python=3.10.6 Активировать среду conda активирует StableDiffusion Подтвердить выбранную среду список конвертов conda Запускаем локальный веб-сервер webui-user.bat Дождитесь “Запуск по локальному URL-адресу: http://127.0.0.1:7860” и откройте этот URI. ``` *(Необязательно)* Перейдите на CompVis и загрузите последнюю модель, например 1.4 и распакуйте его в пример: ударить GIT\\StableDiffusion\\models\\Stable-диффузия после этого перезапустите сервер, перезапустив приглашение Anaconda и ударить webui-user.bat Альтернативные значения по умолчанию, которые стоит попробовать: Попробуйте euler a (Ancestral Euler) с более высокими шагами выборки, например: 40 или другие со 100. Установите для параметра «Настройки» &gt; «Пользовательский интерфейс» &gt; «Показывать ход создания образа через каждые N шагов выборки» значение 1 и выберите детерминированное значение Исходное число. Можно визуально увидеть, как происходит разделение изображений, и записать .gif с помощью ScreenToGif. Используйте Восстановить лица. Как правило, лучшие результаты, но это качество достигается за счет скорости."
  },"/sdwui-docs/install-on-apple/": {
    "title": "установить на Apple",
    "keywords": "development",
    "url": "/sdwui-docs/install-on-apple/",
    "body": "Пользователи Mac: отправьте отзыв о том, работают ли эти инструкции для вас или нет, и если что-то неясно или у вас все еще есть проблемы с установкой, которые в настоящее время не упомянуты здесь. Важные заметки Currently most functionality in the web UI works correctly on macOS, with the most notable exceptions being CLIP interrogator and training. Although training does seem to work, it is incredibly slow and consumes an excessive amount of memory. CLIP interrogator can be used but it doesn’t work correctly with the GPU acceleration macOS uses so the default configuration will run it entirely via CPU (which is slow). Most samplers are known to work with the only exception being the PLMS sampler when using the Stable Diffusion 2.0 model. Generated images with GPU acceleration on macOS should usually match or almost match generated images on CPU with the same settings and seed. Automatic installation Новая установка: Если Homebrew не установлен, следуйте инструкциям на странице https://brew.sh, чтобы установить его. Держите окно терминала открытым и следуйте инструкциям в разделе «Следующие шаги», чтобы добавить Homebrew в PATH. Откройте новое окно терминала и запустите brew install cmake protobuf rust python@3.10 git wget Клонируйте репозиторий веб-интерфейса, запустив git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui. Поместите модели/контрольные точки Stable Diffusion, которые вы хотите использовать, в stable-diffusion-webui/models/Stable-diffusion. Если у вас их нет, см. Загрузка моделей стабильной диффузии ниже. cd stable-diffusion-webui, а затем ./webui.sh, чтобы запустить веб-интерфейс. Виртуальная среда Python будет создана и активирована с помощью venv, а все оставшиеся недостающие зависимости будут автоматически загружены и установлены. Чтобы перезапустить процесс веб-интерфейса позже, снова запустите ./webui.sh. Обратите внимание, что веб-интерфейс не обновляется автоматически; для обновления запустите git pull перед запуском ./webui.sh. Существующая установка: Если у вас уже есть установка веб-интерфейса, созданная с помощью setup_mac.sh, удалите файл run_webui_mac.sh и папку repositories из папки stable-diffusion-webui. Затем запустите git pull, чтобы обновить веб-интерфейс, а затем ./webui.sh, чтобы запустить его. Загрузка моделей стабильной диффузии If you don’t have any models to use, Stable Diffusion models can be downloaded from Hugging Face. To download, click on a model and then click on the Files and versions header. Look for files listed with the “.ckpt” or “.safetensors” extensions, and then click the down arrow to the right of the file size to download them. Some popular official Stable Diffusion models are: Stable DIffusion 1.4 (sd-v1-4.ckpt) Stable Diffusion 1.5 (v1-5-pruned-emaonly.ckpt) Stable Diffusion 1.5 Inpainting (sd-v1-5-inpainting.ckpt) Stable Diffusion 2.0 and 2.1 require both a model and a configuration file, and image width &amp; height will need to be set to 768 or higher when generating images: Stable Diffusion 2.0 (768-v-ema.ckpt) Stable Diffusion 2.1 (v2-1_768-ema-pruned.ckpt) For the configuration file, hold down the option key on the keyboard and click here to download v2-inference-v.yaml (it may download as v2-inference-v.yaml.yml). In Finder select that file then go to the menu and select File &gt; Get Info. In the window that appears select the filename and change it to the filename of the model, except with the file extension .yaml instead of .ckpt, press return on the keyboard (confirm changing the file extension if prompted), and place it in the same folder as the model (e.g. if you downloaded the 768-v-ema.ckpt model, rename it to 768-v-ema.yaml and put it in stable-diffusion-webui/models/Stable-diffusion along with the model). Also available is a Stable Diffusion 2.0 depth model (512-depth-ema.ckpt). Download the v2-midas-inference.yaml configuration file by holding down option on the keyboard and clicking here, then rename it with the .yaml extension in the same way as mentioned above and put it in stable-diffusion-webui/models/Stable-diffusion along with the model. Note that this model works at image dimensions of 512 width/height or higher instead of 768. Troubleshooting Веб-интерфейс не запускается: Если вы столкнулись с ошибками при попытке запустить веб-интерфейс с помощью ./webui.sh, попробуйте удалить папки repositories и venv из папки stable-diffusion-webui, а затем обновите веб-интерфейс с помощью git pull перед повторным запуском ./webui.sh. Плохая работа: В настоящее время ускорение GPU в macOS использует lot памяти. Если производительность низкая (если для создания изображения 512x512 с 20 шагами с любым сэмплером требуется больше минуты), сначала попробуйте начать с параметра командной строки --opt-split-attention-v1 (например, ./webui. sh --opt-split-attention-v1) и посмотрите, поможет ли это. Если это не имеет большого значения, откройте приложение «Мониторинг активности», расположенное в /Applications/Utilities, и проверьте график нехватки памяти на вкладке «Память». Если нехватка памяти отображается красным цветом при создании изображения, закройте процесс веб-интерфейса, а затем добавьте параметр командной строки --medvram (например, ./webui.sh --opt-split-attention-v1 -- медврам). Если производительность по-прежнему низкая, а нехватка памяти с этой опцией по-прежнему красная, то вместо этого попробуйте --lowvram (т.е. ./webui.sh --opt-split-attention-v1 --lowvram). Если для создания изображения 512x512 с 20 шагами с любым сэмплером по-прежнему требуется больше нескольких минут, возможно, вам нужно отключить ускорение графического процессора. Откройте webui-user.sh в Xcode и измените #export COMMANDLINE_ARGS=\"\" на export COMMANDLINE_ARGS=\"--skip-torch-cuda-test --no-half --use-cpu all\". Discussions/Feedback here: https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/5461"
  },"/sdwui-docs/list-of-time-zones/": {
    "title": "Список часовых поясов",
    "keywords": "Guides",
    "url": "/sdwui-docs/list-of-time-zones/",
    "body": "Вы можете создать список допустимых часовых поясов, запустив этот скрипт Python import pytz for tz in pytz.all_timezones: print(tz) Или вы можете сослаться на этот предварительно сгенерированный список (может быть устаревшим). Africa/Accra Africa/Addis_Ababa Africa/Algiers Africa/Asmara Africa/Asmera Africa/Bamako Africa/Bangui Africa/Banjul Africa/Bissau Africa/Blantyre Africa/Brazzaville Africa/Bujumbura Africa/Cairo Africa/Casablanca Africa/Ceuta Africa/Conakry Africa/Dakar Africa/Dar_es_Salaam Africa/Djibouti Africa/Douala Africa/El_Aaiun Africa/Freetown Africa/Gaborone Africa/Harare Africa/Johannesburg Africa/Juba Africa/Kampala Africa/Khartoum Africa/Kigali Africa/Kinshasa Africa/Lagos Africa/Libreville Africa/Lome Africa/Luanda Africa/Lubumbashi Africa/Lusaka Africa/Malabo Africa/Maputo Africa/Maseru Africa/Mbabane Africa/Mogadishu Africa/Monrovia Africa/Nairobi Africa/Ndjamena Africa/Niamey Africa/Nouakchott Africa/Ouagadougou Africa/Porto-Novo Africa/Sao_Tome Africa/Timbuktu Africa/Tripoli Africa/Tunis Africa/Windhoek America/Adak America/Anchorage America/Anguilla America/Antigua America/Araguaina America/Argentina/Buenos_Aires America/Argentina/Catamarca America/Argentina/ComodRivadavia America/Argentina/Cordoba America/Argentina/Jujuy America/Argentina/La_Rioja America/Argentina/Mendoza America/Argentina/Rio_Gallegos America/Argentina/Salta America/Argentina/San_Juan America/Argentina/San_Luis America/Argentina/Tucuman America/Argentina/Ushuaia America/Aruba America/Asuncion America/Atikokan America/Atka America/Bahia America/Bahia_Banderas America/Barbados America/Belem America/Belize America/Blanc-Sablon America/Boa_Vista America/Bogota America/Boise America/Buenos_Aires America/Cambridge_Bay America/Campo_Grande America/Cancun America/Caracas America/Catamarca America/Cayenne America/Cayman America/Chicago America/Chihuahua America/Coral_Harbour America/Cordoba America/Costa_Rica America/Creston America/Cuiaba America/Curacao America/Danmarkshavn America/Dawson America/Dawson_Creek America/Denver America/Detroit America/Dominica America/Edmonton America/Eirunepe America/El_Salvador America/Ensenada America/Fort_Nelson America/Fort_Wayne America/Fortaleza America/Glace_Bay America/Godthab America/Goose_Bay America/Grand_Turk America/Grenada America/Guadeloupe America/Guatemala America/Guayaquil America/Guyana America/Halifax America/Havana America/Hermosillo America/Indiana/Indianapolis America/Indiana/Knox America/Indiana/Marengo America/Indiana/Petersburg America/Indiana/Tell_City America/Indiana/Vevay America/Indiana/Vincennes America/Indiana/Winamac America/Indianapolis America/Inuvik America/Iqaluit America/Jamaica America/Jujuy America/Juneau America/Kentucky/Louisville America/Kentucky/Monticello America/Knox_IN America/Kralendijk America/La_Paz America/Lima America/Los_Angeles America/Louisville America/Lower_Princes America/Maceio America/Managua America/Manaus America/Marigot America/Martinique America/Matamoros America/Mazatlan America/Mendoza America/Menominee America/Merida America/Metlakatla America/Mexico_City America/Miquelon America/Moncton America/Monterrey America/Montevideo America/Montreal America/Montserrat America/Nassau America/New_York America/Nipigon America/Nome America/Noronha America/North_Dakota/Beulah America/North_Dakota/Center America/North_Dakota/New_Salem America/Nuuk America/Ojinaga America/Panama America/Pangnirtung America/Paramaribo America/Phoenix America/Port-au-Prince America/Port_of_Spain America/Porto_Acre America/Porto_Velho America/Puerto_Rico America/Punta_Arenas America/Rainy_River America/Rankin_Inlet America/Recife America/Regina America/Resolute America/Rio_Branco America/Rosario America/Santa_Isabel America/Santarem America/Santiago America/Santo_Domingo America/Sao_Paulo America/Scoresbysund America/Shiprock America/Sitka America/St_Barthelemy America/St_Johns America/St_Kitts America/St_Lucia America/St_Thomas America/St_Vincent America/Swift_Current America/Tegucigalpa America/Thule America/Thunder_Bay America/Tijuana America/Toronto America/Tortola America/Vancouver America/Virgin America/Whitehorse America/Winnipeg America/Yakutat America/Yellowknife Antarctica/Casey Antarctica/Davis Antarctica/DumontDUrville Antarctica/Macquarie Antarctica/Mawson Antarctica/McMurdo Antarctica/Palmer Antarctica/Rothera Antarctica/South_Pole Antarctica/Syowa Antarctica/Troll Antarctica/Vostok Arctic/Longyearbyen Asia/Aden Asia/Almaty Asia/Amman Asia/Anadyr Asia/Aqtau Asia/Aqtobe Asia/Ashgabat Asia/Ashkhabad Asia/Atyrau Asia/Baghdad Asia/Bahrain Asia/Baku Asia/Bangkok Asia/Barnaul Asia/Beirut Asia/Bishkek Asia/Brunei Asia/Calcutta Asia/Chita Asia/Choibalsan Asia/Chongqing Asia/Chungking Asia/Colombo Asia/Dacca Asia/Damascus Asia/Dhaka Asia/Dili Asia/Dubai Asia/Dushanbe Asia/Famagusta Asia/Gaza Asia/Harbin Asia/Hebron Asia/Ho_Chi_Minh Asia/Hong_Kong Asia/Hovd Asia/Irkutsk Asia/Istanbul Asia/Jakarta Asia/Jayapura Asia/Jerusalem Asia/Kabul Asia/Kamchatka Asia/Karachi Asia/Kashgar Asia/Kathmandu Asia/Katmandu Asia/Khandyga Asia/Kolkata Asia/Krasnoyarsk Asia/Kuala_Lumpur Asia/Kuching Asia/Kuwait Asia/Macao Asia/Macau Asia/Magadan Asia/Makassar Asia/Manila Asia/Muscat Asia/Nicosia Asia/Novokuznetsk Asia/Novosibirsk Asia/Omsk Asia/Oral Asia/Phnom_Penh Asia/Pontianak Asia/Pyongyang Asia/Qatar Asia/Qostanay Asia/Qyzylorda Asia/Rangoon Asia/Riyadh Asia/Saigon Asia/Sakhalin Asia/Samarkand Asia/Seoul Asia/Shanghai Asia/Singapore Asia/Srednekolymsk Asia/Taipei Asia/Tashkent Asia/Tbilisi Asia/Tehran Asia/Tel_Aviv Asia/Thimbu Asia/Thimphu Asia/Tokyo Asia/Tomsk Asia/Ujung_Pandang Asia/Ulaanbaatar Asia/Ulan_Bator Asia/Urumqi Asia/Ust-Nera Asia/Vientiane Asia/Vladivostok Asia/Yakutsk Asia/Yangon Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Bermuda Atlantic/Canary Atlantic/Cape_Verde Atlantic/Faeroe Atlantic/Faroe Atlantic/Jan_Mayen Atlantic/Madeira Atlantic/Reykjavik Atlantic/South_Georgia Atlantic/St_Helena Atlantic/Stanley Australia/ACT Australia/Adelaide Australia/Brisbane Australia/Broken_Hill Australia/Canberra Australia/Currie Australia/Darwin Australia/Eucla Australia/Hobart Australia/LHI Australia/Lindeman Australia/Lord_Howe Australia/Melbourne Australia/NSW Australia/North Australia/Perth Australia/Queensland Australia/South Australia/Sydney Australia/Tasmania Australia/Victoria Australia/West Australia/Yancowinna Brazil/Acre Brazil/DeNoronha Brazil/East Brazil/West CET CST6CDT Canada/Atlantic Canada/Central Canada/Eastern Canada/Mountain Canada/Newfoundland Canada/Pacific Canada/Saskatchewan Canada/Yukon Chile/Continental Chile/EasterIsland Cuba EET EST EST5EDT Egypt Eire Etc/GMT Etc/GMT+0 Etc/GMT+1 Etc/GMT+10 Etc/GMT+11 Etc/GMT+12 Etc/GMT+2 Etc/GMT+3 Etc/GMT+4 Etc/GMT+5 Etc/GMT+6 Etc/GMT+7 Etc/GMT+8 Etc/GMT+9 Etc/GMT-0 Etc/GMT-1 Etc/GMT-10 Etc/GMT-11 Etc/GMT-12 Etc/GMT-13 Etc/GMT-14 Etc/GMT-2 Etc/GMT-3 Etc/GMT-4 Etc/GMT-5 Etc/GMT-6 Etc/GMT-7 Etc/GMT-8 Etc/GMT-9 Etc/GMT0 Etc/Greenwich Etc/UCT Etc/UTC Etc/Universal Etc/Zulu Europe/Amsterdam Europe/Andorra Europe/Astrakhan Europe/Athens Europe/Belfast Europe/Belgrade Europe/Berlin Europe/Bratislava Europe/Brussels Europe/Bucharest Europe/Budapest Europe/Busingen Europe/Chisinau Europe/Copenhagen Europe/Dublin Europe/Gibraltar Europe/Guernsey Europe/Helsinki Europe/Isle_of_Man Europe/Istanbul Europe/Jersey Europe/Kaliningrad Europe/Kiev Europe/Kirov Europe/Kyiv Europe/Lisbon Europe/Ljubljana Europe/London Europe/Luxembourg Europe/Madrid Europe/Malta Europe/Mariehamn Europe/Minsk Europe/Monaco Europe/Moscow Europe/Nicosia Europe/Oslo Europe/Paris Europe/Podgorica Europe/Prague Europe/Riga Europe/Rome Europe/Samara Europe/San_Marino Europe/Sarajevo Europe/Saratov Europe/Simferopol Europe/Skopje Europe/Sofia Europe/Stockholm Europe/Tallinn Europe/Tirane Europe/Tiraspol Europe/Ulyanovsk Europe/Uzhgorod Europe/Vaduz Europe/Vatican Europe/Vienna Europe/Vilnius Europe/Volgograd Europe/Warsaw Europe/Zagreb Europe/Zaporozhye Europe/Zurich GB GB-Eire GMT GMT+0 GMT-0 GMT0 Greenwich HST Hongkong Iceland Indian/Antananarivo Indian/Chagos Indian/Christmas Indian/Cocos Indian/Comoro Indian/Kerguelen Indian/Mahe Indian/Maldives Indian/Mauritius Indian/Mayotte Indian/Reunion Iran Israel Jamaica Japan Kwajalein Libya MET MST MST7MDT Mexico/BajaNorte Mexico/BajaSur Mexico/General NZ NZ-CHAT Navajo PRC PST8PDT Pacific/Apia Pacific/Auckland Pacific/Bougainville Pacific/Chatham Pacific/Chuuk Pacific/Easter Pacific/Efate Pacific/Enderbury Pacific/Fakaofo Pacific/Fiji Pacific/Funafuti Pacific/Galapagos Pacific/Gambier Pacific/Guadalcanal Pacific/Guam Pacific/Honolulu Pacific/Johnston Pacific/Kanton Pacific/Kiritimati Pacific/Kosrae Pacific/Kwajalein Pacific/Majuro Pacific/Marquesas Pacific/Midway Pacific/Nauru Pacific/Niue Pacific/Norfolk Pacific/Noumea Pacific/Pago_Pago Pacific/Palau Pacific/Pitcairn Pacific/Pohnpei Pacific/Ponape Pacific/Port_Moresby Pacific/Rarotonga Pacific/Saipan Pacific/Samoa Pacific/Tahiti Pacific/Tarawa Pacific/Tongatapu Pacific/Truk Pacific/Wake Pacific/Wallis Pacific/Yap Poland Portugal ROC ROK Singapore Turkey UCT US/Alaska US/Aleutian US/Arizona US/Central US/East-Indiana US/Eastern US/Hawaii US/Indiana-Starke US/Michigan US/Mountain US/Pacific US/Samoa UTC Universal W-SU WET Zulu"
  },"/sdwui-docs/localization/": {
    "title": "Локализация",
    "keywords": "Guides",
    "url": "/sdwui-docs/localization/",
    "body": "Использование файлов локализации Предполагаемый способ локализации сейчас — через расширения. Видеть: https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Разработка-расширения Создание файлов локализации Перейдите в настройки и нажмите кнопку «Загрузить шаблон локализации» внизу. Это загрузит шаблон для локализации, который вы сможете редактировать. Обновление старой локализации новыми ключами Этот репозиторий содержит старые потерянные локализации. Если вы хотите обновить их новыми ключами, вы можете использовать следующий скрипт: import json files=['localization_template.json', 'old_localization.json'] with open('new_localization.json', \"w\") as outfile: res = dict() for f in files: dct = dict(json.load(open(f, \"r\").read())) res.update(dct) outfile.write(res) Затем переведите то, что было добавлено."
  },"/sdwui-docs/negative-prompt/": {
    "title": "Отрицательное приглашение",
    "keywords": "Guides",
    "url": "/sdwui-docs/negative-prompt/",
    "body": "Отрицательное приглашение — это способ использования Stable Diffusion таким образом, чтобы пользователь мог указать то, что он не хочет видеть, без дополнительной нагрузки или требований к модели. Насколько я знаю, я был первым, кто использовал этот подход; коммит, который его добавляет, — 757bb7c4. Эта функция нашла огромную популярность среди пользователей, которые удаляют с ее помощью обычные деформации Stable Diffusion, такие как лишние конечности. В дополнение к возможности указать, что вы не хотите видеть, что иногда возможно с помощью обычной подсказки, а иногда нет, это позволяет вам сделать это без использования каких-либо ваших разрешенных 75 токенов, из которых состоит подсказка. . Способ работы отрицательного приглашения заключается в использовании указанного пользователем текста вместо пустой строки для unconditional_conditioning при выполнении выборки. Вот (упрощенный) код из txt2img.py: # prompts = [\"a castle in a forest\"] # batch_size = 1 c = model.get_learned_conditioning(prompts) uc = model.get_learned_conditioning(batch_size * [\"\"]) samples_ddim, _ = sampler.sample(conditioning=c, unconditional_conditioning=uc, [...]) Это запускает сэмплер, который многократно: убирает шумы с картинки, чтобы она больше походила на вашу подсказку (кондиционирование) устраняет шум изображения, делая его более похожим на пустую подсказку (unconditional_conditioning) смотрит на разницу между ними и использует ее для создания набора изменений для зашумленного изображения (разные сэмплеры делают эту часть по-разному) Чтобы использовать отрицательную подсказку, все, что нужно, это: # prompts = [\"a castle in a forest\"] # negative_prompts = [\"grainy, fog\"] c = model.get_learned_conditioning(prompts) uc = model.get_learned_conditioning(negative_prompts) samples_ddim, _ = sampler.sample(conditioning=c, unconditional_conditioning=uc, [...]) Затем сэмплер рассмотрит различия между изображением, очищенным от шума, чтобы оно выглядело как ваша подсказка (замок), и изображением, очищенным от шума, чтобы оно выглядело как ваша отрицательная подсказка (зернистость, туман), и попытается сдвинуть окончательные результаты к прежнему. и от последнего. Примеры: a colorful photo of a castle in the middle of a forest with trees and (((bushes))), by Ismail Inceoglu, ((((shadows)))), ((((high contrast)))), dynamic shading, ((hdr)), detailed vegetation, digital painting, digital drawing, detailed painting, a detailed digital painting, gothic art, featured on deviantart Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 749109862, Size: 896x448, Model hash: 7460a6fa отрицательная подсказка изображение нет туман зернистый туман, зернистый туман, зернистый, фиолетовый"
  },"/sdwui-docs/online-services/": {
    "title": "Онлайн-сервисы",
    "keywords": "Getting started",
    "url": "/sdwui-docs/online-services/",
    "body": "Совместная работа с Google поддерживается TheLastBen поддерживается камендуру поддерживается ddPn08 поддерживается Akaibu Colab, оригинал AUTOMATIC1111, устарел. Российская коллаборация, поддерживается PR0LAPSE Бумажное пространство поддерживается Cyberes Каггл поддерживается камендуру Лаборатория SageMaker Studio поддерживается фрактальностью Обнимающее лицо поддерживается камендуру Руководства по установке azure-ml - (commit)"
  },"/sdwui-docs/optimizations/": {
    "title": "Optimizations",
    "keywords": "Guides",
    "url": "/sdwui-docs/optimizations/",
    "body": "A number of optimization can be enabled by commandline arguments: commandline argument explanation --xformers Use xformers library. Great improvement to memory consumption and speed. Windows version installs binaries mainained by C43H66N12O12S2. Will only be enabled on small subset of configuration because that’s what we have binaries for. Documentation --force-enable-xformers Enables xformers above regardless of whether the program thinks you can run it or not. Do not report bugs you get running this. --opt-split-attention Cross attention layer optimization significantly reducing memory use for almost no cost (some report improved preformance with it). Black magic. On by default for torch.cuda, which includes both NVidia and AMD cards. --disable-opt-split-attention Disables the optimization above. --opt-split-attention-v1 Uses an older version of the optimization above that is not as memory hungry (it will use less VRAM, but will be more limiting in the maximum size of pictures you can make). --medvram Makes the Stable Diffusion model consume less VRAM by splitting it into three parts - cond (for transforming text into numerical representation), first_stage (for converting a picture into latent space and back), and unet (for actual denoising of latent space) and making it so that only one is in VRAM at all times, sending others to CPU RAM. Lowers performance, but only by a bit - except if live previews are enabled. --lowvram An even more thorough optimization of the above, splitting unet into many modules, and only one module is kept in VRAM. Devastating for performance. *do-not-batch-cond-uncond Prevents batching of positive and negative prompts during sampling, which essentially lets you run at 0.5 batch size, saving a lot of memory. Decreases performance. Not a command line option, but an optimization implicitly enabled by using --medvram or --lowvram. --always-batch-cond-uncond Disables the optimization above. Only makes sense together with --medvram or --lowvram --opt-channelslast Changes torch memory type for stable diffusion to channels last. Effects not closely studied. Extra tips (Windows): https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/3889 Disable Hardware GPU scheduling. disable browser hardware acceleration Go in nvidia control panel, 3d parameters, and change power profile to “maximum performance”"
  },"/sdwui-docs/": {
    "title": "Стабильный диффузионный веб-интерфейс",
    "keywords": "Getting started",
    "url": "/sdwui-docs/",
    "body": "Интерфейс браузера на основе библиотеки Gradio для Stable Diffusion. Проверьте вики-страницу пользовательские сценарии на наличие дополнительных сценариев, разработанных пользователями. Функции Подробная демонстрация функций с изображениями: Оригинальные режимы txt2img и img2img Установить и запустить скрипт одним щелчком мыши (но вы все равно должны установить python и git) Окрашивание Покраска Цветной эскиз Матрица подсказок Стабильный диффузионный апскейл Внимание, укажите части текста, которым модель должна уделить больше внимания мужчина в ((смокинге)) - будет уделять больше внимания смокингу мужчина в (смокинг:1.21) - альтернативный синтаксис выберите текст и нажмите ctrl+up или ctrl+down, чтобы автоматически настроить внимание на выделенный текст (код предоставлен анонимным пользователем) Loopback, запустить обработку img2img несколько раз График X/Y, способ рисования двухмерного графика изображений с разными параметрами Текстовая инверсия иметь столько вложений, сколько хотите, и использовать для них любые имена, которые вам нравятся использовать несколько вложений с разным количеством векторов на токен работает с числами с плавающей запятой половинной точности тренируй вложения на 8гб (также отчеты о работе 6гб) Вкладка «Дополнительно» с: GFPGAN, нейронная сеть, фиксирующая лица CodeFormer, инструмент восстановления лица как альтернатива GFPGAN RealESRGAN, апскейлер нейронной сети ESRGAN, апскейлер нейронной сети с множеством сторонних моделей SwinIR и Swin2SR(см. здесь), апскейлеры нейронных сетей LDSR, повышение разрешения сверхвысокого разрешения со скрытой диффузией Изменение параметров соотношения сторон Выбор метода отбора проб Отрегулируйте значения eta сэмплера (множитель шума) Более продвинутые параметры настройки шума Прерывание обработки в любое время Поддержка видеокарты 4 ГБ (также сообщается о работе 2 ГБ) Правильные семена для партий Проверка длины токена подсказки в реальном времени Параметры генерации параметры, которые вы использовали для создания изображений, сохраняются вместе с этим изображением в чанках PNG для PNG, в EXIF ​​для JPEG можно перетащить изображение на вкладку информации PNG, чтобы восстановить параметры генерации и автоматически скопировать их в пользовательский интерфейс можно отключить в настройках перетащите изображение/текстовые параметры в окно подсказки Кнопка «Чтение параметров генерации», загружает параметры в поле подсказки в пользовательский интерфейс. Страница настроек Запуск произвольного кода Python из пользовательского интерфейса (для включения необходимо запустить с параметром –allow-code) Подсказки при наведении курсора для большинства элементов пользовательского интерфейса Можно изменить значения по умолчанию/микшер/максимум/шаг для элементов пользовательского интерфейса с помощью текстовой конфигурации. Кнопка случайного исполнителя Поддержка тайлинга, флажок для создания изображений, которые могут быть мозаичными, как текстуры. Индикатор выполнения и предварительный просмотр генерации живого изображения Отрицательное приглашение, дополнительное текстовое поле, которое позволяет вам перечислить то, что вы не хотите видеть в сгенерированном изображении. Стили, способ сохранить часть приглашения и легко применить их позже через раскрывающийся список Вариации, способ создания одного и того же изображения, но с небольшими отличиями. Изменение размера семени, способ создания того же изображения, но с немного другим разрешением Опросчик CLIP, кнопка, которая пытается угадать подсказку по изображению Редактирование подсказки, способ изменить подсказку в середине поколения, скажем, начать делать арбуз и переключиться на аниме-девушку на полпути. Пакетная обработка, обработка группы файлов с помощью img2img Img2img Альтернативный метод обратного Эйлера контроля перекрестного внимания Highres Fix, удобная опция для создания изображений высокого разрешения в один клик без обычных искажений Перезагрузка чекпоинтов на лету Checkpoint Merger, вкладка, позволяющая объединить до 3-х контрольных точек в одну Пользовательские сценарии со многими расширениями от сообщества Composable-Diffusion, способ одновременного использования нескольких подсказок. разделяйте подсказки с помощью заглавной буквы И также поддерживает веса для подсказок: «кошка: 1,2 И собака И пингвин: 2,2» Нет лимита токенов для подсказок (оригинальная стабильная диффузия позволяет использовать до 75 токенов) Интеграция DeepDanbooru, создание тегов в стиле danbooru для подсказок аниме. xformers, значительное увеличение скорости для некоторых карт: (добавьте –xformers в аргументы командной строки) через расширение: вкладка «История»: удобно просматривать, направлять и удалять изображения в пользовательском интерфейсе. Создать навсегда вариант вкладка “Обучение” варианты гиперсетей и вложений Предварительная обработка изображений: обрезка, зеркальное отображение, автопометка с использованием BLIP или deepdanbooru (для аниме) Пропустить клип Используйте гиперсети Используйте VAE Расчетное время завершения в индикаторе выполнения API Поддержка выделенной модели рисования от RunwayML. через расширение: Эстетические градиенты, способ создания изображений с определенной эстетикой с помощью встраивания изображений клипов (реализация https: //github.com/vicgalle/stable-diffusion-aesthetic-gradients) Поддержка Stable Diffusion 2.0 - см. wiki по инструкции Установка и запуск Убедитесь, что необходимые зависимости соблюдены, и следуйте инструкциям, доступным для обоих NVidia (рекомендуется) и AMD графические процессоры. В качестве альтернативы используйте онлайн-сервисы (например, Google Colab): Список онлайн-сервисов Автоматическая установка в Windows Установите Python 3.10.6, отметив «Добавить Python в PATH». Установите git. Загрузите репозиторий stable-diffusion-webui, например, запустив git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git. Поместите model.ckpt в каталог models (см. зависимости, чтобы узнать, где его взять). *(Необязательно)* Поместите GFPGANv1.4.pth в базовый каталог вместе с webui.py (см. зависимости для того, чтобы узнать, где его взять). Запустите webui-user.bat из проводника Windows как обычный пользователь без прав администратора. Автоматическая установка в Linux Установите зависимости: # Debian-based: sudo apt install wget git python3 python3-venv # Red Hat-based: sudo dnf install wget git python3 # Arch-based: sudo pacman -S wget git python3 Чтобы установить в /home/$(whoami)/stable-diffusion-webui/, запустите: bash &lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh) Установка на Apple Silicon Найдите инструкции здесь. Содействие Вот как добавить код в этот репозиторий: Contributing Документация Документация была перемещена из этого README в [вики] проекта (https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki). Кредиты Стабильная диффузия - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformers k-диффузия - https://github.com/crowsonkb/k-diffusion.git GFPGAN - https://github.com/TencentARC/GFPGAN.git CodeFormer - https://github.com/sczhou/CodeFormer ЭСРГАН - https://github.com/xinntao/ESRGAN SwinIR - https://github.com/JingyunLiang/SwinIR Swin2SR - https://github.com/mv-lab/swin2sr ЛДСР - https://github.com/Hafiidz/latent-diffusion МиДаС - https://github.com/isl-org/MiDaS Идеи по оптимизации - https://github.com/basujindal/stable-diffusion Оптимизация слоя Cross Attention - Doggettx - https://github.com/Doggettx/stable-diffusion, оригинальная идея для оперативного редактирования. Оптимизация уровня перекрестного внимания - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (первоначально http://github.com/lstein/stable-diffusion) Текстовая инверсия - Ринон Гал - https://github.com/rinongal/textual_inversion (мы не используем его код, но мы используем его идеи). Идея для апскейла SD - https://github.com/jquesnelle/txt2imghd Генерация шума для перекрашивания мк2 - https://github.com/parlance-zz/g-diffuser-bot Идея опросчика CLIP и заимствование кода - https://github.com/pharmapsychotic/clip-interrogator Идея компонуемой диффузии - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch xformers - https://github.com/facebookresearch/xformers DeepDanbooru - опросчик для аниме-диффузоров https://github.com/KichangKim/DeepDanbooru Совет по безопасности - RyotaK Исходный скрипт Gradio - опубликован на 4chan анонимным пользователем. Спасибо Анонимный пользователь. (Ты)"
  },"/sdwui-docs/tests": {
    "title": "Тесты",
    "keywords": "development",
    "url": "/sdwui-docs/tests",
    "body": "Есть тесты, которые просто проверяют, работает ли базовое создание образов через API. Чтобы запустить тесты, добавьте --tests в качестве аргумента командной строки для launch.py вместе с другими аргументами командной строки: python launch.py --skip-torch-cuda-test --deepdanbooru --no-half-vae --tests Вы найдете выходные данные основной программы в test/stdout.txt и test/stderr.txt."
  },"/sdwui-docs/textual-inversion/": {
    "title": "Текстовая инверсия",
    "keywords": "Guides",
    "url": "/sdwui-docs/textual-inversion/",
    "body": "Что такое текстовая инверсия? Текстовая инверсия позволяет обучить крошечную часть нейронной сети на собственных картинках и использовать результаты при генерации новых. В этом контексте встраивание — это название крошечной части нейронной сети, которую вы обучили. Результатом обучения является файл .pt или .bin (первый формат используется автором оригинала, второй - библиотекой диффузоров) с вложением в него. Подробнее о том, что такое текстовая инверсия, см. на исходном сайте: https://textual-inversion.github.io/. Использование предварительно обученных эмбеддингов Поместите вложение в каталог «embeddings» и используйте его имя файла в подсказке. Вам не нужно перезапускать программу, чтобы это работало. В качестве примера вот вставка Усада Пекора Тренировалась на модели WD1.2, на 53 картинках ( 119 дополнен) для 19500 шагов, с 8 векторами на настройку токена. Картины, которые он генерирует: portrait of usada pekora Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 4077357776, Size: 512x512, Model hash: 45dee52b Вы можете комбинировать несколько вложений в одном приглашении: portrait of usada pekora, mignon Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 4077357776, Size: 512x512, Model hash: 45dee52b Будьте очень осторожны с тем, какую модель вы используете со своими встраиваниями: они хорошо работают с моделью, которую вы использовали во время обучения, и не так хорошо с другими моделями. Например, вот приведенная выше модель встраивания и стабильной диффузии vanilla 1.4: portrait of usada pekora Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 4077357776, Size: 512x512, Model hash: 7460a6fa Обучающие вложения Вкладка Инверсия текста Экспериментальная поддержка обучающих вложений в пользовательский интерфейс. создать новую пустую вставку, выбрать директорию с изображениями, обучить на ней вставку функция очень сырая, используйте на свой страх и риск я смог воспроизвести результаты, которые я получил с другими репозиториями при обучении аниме-художников стилям, после нескольких десятков тысяч шагов работает с поплавками половинной точности, но нужно поэкспериментировать, чтобы увидеть, будут ли результаты такими же хорошими если у вас достаточно памяти, безопаснее запускать с --no-half --precision full Раздел для пользовательского интерфейса для автоматического запуска предварительной обработки изображений. вы можете прерывать и возобновлять обучение без потери данных (кроме параметров оптимизации AdamW, но, кажется, ни один из существующих репозиториев не сохраняет их, так что общее мнение - они не важны) нет поддержки размеров партии или накопления градиента не должно быть возможности запустить это с флагами --lowvram и --medvram. Объяснение параметров Создание встраивания Имя: имя файла созданного встраивания. Вы также будете использовать этот текст в подсказках при обращении к встраиванию. Текст инициализации: создаваемое встраивание будет изначально заполнено векторами этого текста. Если вы создадите одно векторное вложение с именем «zzzz1234» с «деревом» в качестве текста инициализации и используете его в подсказке без обучения, то подсказка «a zzzz1234 by monet» создаст те же изображения, что и «tree by monet». Количество векторов на токен: размер встраивания. Чем больше это значение, тем больше информации о предмете вы сможете уместить во вложение, но и тем больше слов оно уберет из вашего оперативного пособия. При стабильной диффузии у вас есть ограничение в 75 токенов в подсказке. Если вы используете вставку с 16 векторами в подсказке, у вас останется место для 75 - 16 = 59. Также по моему опыту, чем больше количество векторов, тем больше изображений вам нужно для получения хороших результатов. Предварительная обработка Это берет изображения из каталога, обрабатывает их, чтобы они были готовы к текстовой инверсии, и записывает результаты в другой каталог. Это удобная функция, и вы можете предварительно обработать изображения самостоятельно, если хотите. Исходный каталог: каталог с изображениями Каталог назначения: каталог, в который будут записаны результаты. Создавать перевернутые копии: для каждого изображения также запишите его зеркальную копию. Разделить слишком большое изображение на два: если изображение слишком высокое или широкое, измените его размер, чтобы короткая сторона соответствовала желаемому разрешению, и создайте из него два, возможно, пересекающихся изображения. Использовать заголовок BLIP в качестве имени файла: используйте модель BLIP из опросчика, чтобы добавить заголовок к имени файла. Обучение встраиванию Встраивание: выберите вложение, которое вы хотите обучить, из этого раскрывающегося списка. Скорость обучения: как быстро должно проходить обучение. Опасность установки этого параметра на высокое значение заключается в том, что вы можете нарушить встраивание, если установите слишком высокое значение. Если вы видите «Потеря: nan» в текстовом поле с информацией об обучении, это означает, что вы потерпели неудачу, и встраивание мертво. Со значением по умолчанию этого не должно происходить. В этом параметре можно указать несколько скоростей обучения, используя следующий синтаксис: «0,005:100, 1e-3:1000, 1e-5» — это будет обучать с lr «0,005» для первых 100 шагов, затем «1e-3». ` до 1000 шагов, затем 1e-5 до конца. Каталог набора данных: каталог с изображениями для обучения. Все они должны быть квадратными. Каталог журналов: в этот каталог будут записываться образцы изображений и копии частично обученных вложений. Файл шаблона подсказки: текстовый файл с подсказками, по одной в строке, для обучения модели. Посмотрите файлы в каталоге textual_inversion_templates, чтобы узнать, что вы можете с ними сделать. Используйте style.txt при обучении стилей и subject.txt при обучении внедрению объектов. В файле можно использовать следующие теги: [имя]: имя встраивания [filewords]: слова из имени файла изображения из набора данных. Подробнее см. ниже. Максимальное количество шагов: обучение остановится после того, как будет выполнено это количество шагов. Шаг — это когда одно изображение (или один пакет изображений, но пакеты в настоящее время не поддерживаются) показывается модели и используется для улучшения встраивания. если вы прервете тренировку и возобновите ее позже, количество шагов сохранится. Сохранение изображений с встраиванием в виде фрагментов PNG: каждый раз, когда создается изображение, оно объединяется с последним зарегистрированным встраиванием и сохраняется в image_embeddings в формате, которым можно поделиться как изображением и поместить в папку встраивания. и загружен. Подсказка для предварительного просмотра: если она не пуста, эта подсказка будет использоваться для создания изображений для предварительного просмотра. Если пусто, будет использоваться подсказка из обучения. файловые слова [filewords] — это тег для файла шаблона подсказки, который позволяет вам вставлять текст из имени файла в подсказку. По умолчанию расширение файла удаляется, а также все цифры и дефисы (-) в начале имени файла. Таким образом, это имя файла: 000001-1-a man in suit.png станет этим текстом для подсказки: a man in suit. Форматирование текста в имени файла оставлено как есть. Можно использовать опции Filename word regex и Filename join string, чтобы изменить текст из имени файла: например, со словом regex = \\w+ и join string = , файл, указанный выше, создаст этот текст. : а, мужчина, в, костюме. регулярное выражение используется для извлечения слов из текста (и это ['a', 'man', 'in', 'suit', ]), а соединяющая строка (‘, ‘) помещается между этими словами для создания одного текст: а, мужчина, в, костюме. Также можно создать текстовый файл с тем же именем, что и у изображения (000001-1-мужчина в костюме.txt) и просто поместить туда текст подсказки. Параметры имени файла и регулярного выражения использоваться не будут. Сторонние репозитории Я успешно обучил вложения, используя эти репозитории: nicolai256 lstein Другие варианты — тренироваться на колабах и/или использовать библиотеку диффузоров, о которой я ничего не знаю. Поиск вложений онлайн библиотека концепций обнимающего лица - много разных вложений, но 16777216c - NSFW, стиль аниме-художника таинственного незнакомца. cattoroboto - несколько вложений аниме от анона. viper1 - NSFW, пушистые девочки. вставки анона - NSFW, художники аниме. rentry - страница со ссылками на вложения из множества источников. Гиперсети Гиперсети — это новая (понятно?) концепция тонкой настройки модели без изменения ее веса. Текущий способ обучения гиперсетей — на вкладке текстовой инверсии. Обучение работает так же, как и при текстовой инверсии. Единственное требование — использовать очень-очень низкую скорость обучения, что-то вроде 0,000005 или 0,0000005. Глупый Глупый Руководство Анонимный пользователь написал руководство с картинками по использованию гиперсетей: https://rentry.org/hypernetwork4dumdums Выгружать VAE и CLIP из VRAM при обучении Эта опция на вкладке настроек позволяет сэкономить немного памяти за счет более медленного создания изображения для предварительного просмотра."
  },"/sdwui-docs/troubleshooting/": {
    "title": "Исправление проблем",
    "keywords": "Guides",
    "url": "/sdwui-docs/troubleshooting/",
    "body": "Программа протестирована для работы на Python 3.10.6. Не используйте другие версии, если только вы не ищете проблем. Установщик создает виртуальную среду Python, поэтому ни один из установленных модулей не повлияет на существующие системные установки Python. Чтобы использовать системный python вместо создания виртуальной среды, используйте пользовательский параметр, заменяющий set VENV_DIR=-. Для переустановки с нуля удалите каталоги: venv, repositories. При первом запуске программы отображается путь к интерпретатору python. Если это не тот питон, который вы установили, вы можете указать полный путь в скрипте webui-user; см. Запуск с пользовательскими параметрами. Если нужной версии Python нет в PATH, измените строку set PYTHON=python в webui-user.bat, указав полный путь к исполняемому файлу python. Пример: set PYTHON=B:\\soft\\Python310\\python.exe Требования к установщику из requirements_versions.txt, в котором перечислены версии модулей, специально совместимых с Python 3.10.6. Если это не работает с другими версиями Python, может помочь установка пользовательского параметра set REQS_FILE=requirements.txt. Видеокарты с низким VRAM При работе на видеокартах с небольшим объемом видеопамяти (&lt;=4 ГБ) могут возникать ошибки нехватки памяти. Различные оптимизации могут быть включены с помощью аргументов командной строки, жертвуя некоторой/большой скоростью в пользу использования меньшего количества видеопамяти: Если у вас 4 ГБ видеопамяти и вы хотите создавать изображения размером 512x512 (или, возможно, до 640x640), используйте –medvram. Если у вас 4 ГБ видеопамяти и вы хотите создавать изображения 512x512, но вы получаете сообщение об ошибке нехватки памяти с помощью --medvram, используйте вместо этого --medvram --opt-split-attention. Если у вас 4 ГБ видеопамяти и вы хотите создавать образы 512x512, но вы все еще получаете сообщение об ошибке нехватки памяти, используйте вместо этого --lowvram --always-batch-cond-uncond --opt-split-attention. Если у вас 4 ГБ видеопамяти и вы хотите сделать изображения больше, чем вы можете с помощью --medvram, используйте --lowvram --opt-split-attention. Если у вас больше видеопамяти и вы хотите создавать изображения большего размера, чем обычно (например, 1024x1024 вместо 512x512), используйте --medvram --opt-split-attention. Вы также можете использовать --lowvram, но эффект, скорее всего, будет едва заметен. В противном случае не используйте ни один из них. Зеленый или черный экран Видеокарты При работе на видеокартах, которые не поддерживают числа с плавающей запятой половинной точности (известная проблема с картами 16xx), вместо сгенерированных изображений может появиться зеленый или черный экран. Это можно исправить, используя аргументы командной строки --precision full --no-half при значительном увеличении использования VRAM, что может потребовать --medvram. “Ошибка CUDA: образ ядра недоступен для выполнения на устройстве” после включения xformers Установленные вами xformers несовместимы с вашим графическим процессором. Если вы используете Python 3.10, имеете карту Pascal или выше и работаете в Windows, добавьте --reinstall-xformers --xformers в свой COMMANDLINE_ARGS для обновления до рабочей версии. Удалите –reinstall-xformers после обновления. NameError: имя ‘xformers’ не определено Если вы используете Windows, это означает, что ваш Python слишком стар. Используйте 3.10 Если Linux, вам придется создавать xformers самостоятельно или просто избегать использования xformers."
  },"/sdwui-docs/ui-defaults/": {
    "title": "Изменение настроек интерфейса",
    "keywords": "Getting started",
    "url": "/sdwui-docs/ui-defaults/",
    "body": "Значения по умолчанию в веб-интерфейсе можно изменить, отредактировав файл ui-config.json, который появляется в базовом каталоге, содержащем webui.py, после первого запуска. Изменения применяются только после перезапуска. { \"txt2img/Sampling Steps/value\": 20, \"txt2img/Sampling Steps/minimum\": 1, \"txt2img/Sampling Steps/maximum\": 150, \"txt2img/Sampling Steps/step\": 1, \"txt2img/Batch count/value\": 1, \"txt2img/Batch count/minimum\": 1, \"txt2img/Batch count/maximum\": 32, \"txt2img/Batch count/step\": 1, \"txt2img/Batch size/value\": 1, \"txt2img/Batch size/minimum\": 1, # ... }"
  },"/sdwui-docs/xformers/": {
    "title": "Иксформеры",
    "keywords": "Guides",
    "url": "/sdwui-docs/xformers/",
    "body": "Библиотека Xformers — это дополнительный способ ускорить создание изображений. Для винды нет бинарников кроме одной конкретной конфигурации, но собрать можно самому. Гайд от анонимного пользователя, хотя я думаю он для сборки под линукс: РУКОВОДСТВО ПО СОЗДАНИЮ XFORMERS также включает в себя, как снять с себя ограничение sm86 на новый коммит voldy перейдите в каталог webui источник ./venv/bin/активировать CD репозиторий клон git https://github.com/facebookresearch/xformers.git компакт-диски xformers git submodule update --init --recursive pip install -r requirements.txt pip install -e . Сборка xFormers в Windows от @duckness Если вы используете карту Pascal, Turing, Ampere, Lovelace или Hopper с Python 3.10, вам больше не нужно собирать вручную. Удалите существующие xformers и запустите репозиторий с помощью --xformers. Будет установлено совместимое колесо. Установить VS Build Tools 2022, вам нужна только Разработка рабочего стола с C++ Установить CUDA 11.3 (более поздние версии не тестировались), выбираем custom, нужно только следующее (интеграция с VS возможно не нужна ): Клонируйте репозиторий xFormers (https://github.com/facebookresearch/xformers), создайте venv и активируйте его. git clone https://github.com/facebookresearch/xformers.git cd xformers git submodule update --init --recursive python -m venv venv ./venv/scripts/activate Чтобы избежать проблем с получением версии процессора, установите pyTorch отдельно: pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113 Затем установите остальные зависимости: pip install -r requirements.txt pip install wheel Поскольку CUDA 11.3 довольно старая, вам необходимо принудительно разрешить ее сборку в MS Build Tools 2022. Сделайте $env:NVCC_FLAGS = \"-allow-unsupported-compiler\", если на powershell, или установите NVCC_FLAGS =-allow-unsupported-compiler если на cmd Наконец-то можно собрать xFormers, учтите, что сборка займет много времени (вероятно, 10-20 минут), сначала может жаловаться на какие-то ошибки, но все равно должна компилироваться корректно. НЕОБЯЗАТЕЛЬНЫЙ совет: чтобы еще больше ускорить работу в системах Windows с многоядерными процессорами, установите ninja https://github.com/ninja-build/ninja. Шаги по установке: Загрузите ninja-win.zip с https://github.com/ninja-build/ninja/releases и разархивируйте Поместите ninja.exe в C:\\Windows ИЛИ добавьте полный путь к извлеченному ninja.exe в системный PATH Запустите ninja -h в cmd и проверьте, отображается ли справочное сообщение. Запустите следующие команды, чтобы начать сборку. Он должен автоматически использовать Ninja, никаких дополнительных настроек не требуется. Вы должны увидеть значительно более высокую загрузку ЦП (40%+). ``` сборка python setup.py python setup.py bdist_wheel ``` Это сократило время сборки на ПК с Windows с процессором AMD 5800X с 1,5 часов до 10 минут. Ninja также поддерживается в Linux и MacOS, но у меня нет этих ОС для тестирования, поэтому я не могу предоставить пошаговое руководство. Запустите следующее: ш сборка python setup.py python setup.py bdist_wheel ` In xformers directory, navigate to the dist folder and copy the .whl file to the base directory of stable-diffusion-webui In stable-diffusion-webui directory, install the .whl, change the name of the file in the command below if the name is different: ./venv/скрипты/активировать pip установить xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl Ensure that xformers is activated by launching stable-diffusion-webui with --force-enable-xformers Non-deterministic / unstable / inconsistent results: Known issue. See this list on the discussion page."
  },"/sdwui-docs/api/": {
    "title": "Руководство по API",
    "keywords": "",
    "url": "/sdwui-docs/api/",
    "body": "Во-первых, конечно же, запустить веб-интерфейс с аргументом командной строки --api пример в вашем “webui-user.bat”: set COMMANDLINE_ARGS=--api Это включает API, который можно просмотреть по адресу http://127.0.0.1:7860/docs (или любой URL-адрес +/docs) Основные, которые меня интересуют, это эти два. Давайте сосредоточимся только на /sdapi/v1/txt2img Когда вы раскрываете эту вкладку, она дает пример полезной нагрузки для отправки в API. Я часто использовал это как ссылку. Так это бэкэнд. API в основном говорит, что доступно, что запрашивает и куда это отправить. Теперь, переходя к внешнему интерфейсу, я начну с создания полезной нагрузки с нужными мне параметрами. Примером может быть: payload = { \"prompt\": \"maltese puppy\", \"steps\": 5 } Я могу ввести в полезную нагрузку столько параметров, сколько захочу. API будет использовать значения по умолчанию для всего, что я не установлю. После этого я могу отправить его в API response = requests.post(url=f'http://127.0.0.1:7860/sdapi/v1/txt2img', json=payload) Опять же, этот URL-адрес должен соответствовать URL-адресу веб-интерфейса. Если мы выполним этот код, веб-интерфейс сгенерирует изображение на основе полезной нагрузки. Это здорово, но что потом? Нигде нет изображения… После того, как бэкенд сделает свое дело, API отправляет ответ обратно в переменной, которая была назначена выше: response. Ответ содержит три записи; «изображения», «параметры» и «информация», и мне нужно найти способ получить информацию из этих записей. Во-первых, я поставил эту строку r = response.json(), чтобы было проще работать с ответом. «изображения» - это сгенерированное изображение, чего я больше всего и хочу. Там нет ссылки или чего-то еще; это гигантская строка случайных символов, по-видимому, нам нужно ее расшифровать. Вот как я это делаю: for i in r['images']: image = Image.open(io.BytesIO(base64.b64decode(i.split(\",\",1)[0]))) При этом у нас есть изображение в переменной image, с которым мы можем работать, например, сохраняя его с помощью image.save('output.png'). «параметры» показывают, что было отправлено в API, что может быть полезно, но в данном случае мне нужна «информация». Я использую его для вставки метаданных в изображение, поэтому я могу поместить его в веб-интерфейс PNG Info. Для этого я могу получить доступ к API /sdapi/v1/png-info. Мне нужно будет загрузить в него изображение, которое я получил выше. png_payload = { \"image\": \"data:image/png;base64,\" + i } response2 = requests.post(url=f'http://127.0.0.1:7860/sdapi/v1/png-info', json=png_payload) После этого я могу получить информацию с помощью response2.json().get(\"info\") Пример кода, который должен работать, может выглядеть так: import json import requests import io import base64 from PIL import Image, PngImagePlugin url = \"http://127.0.0.1:7860\" payload = { \"prompt\": \"puppy dog\", \"steps\": 5 } response = requests.post(url=f'{url}/sdapi/v1/txt2img', json=payload) r = response.json() for i in r['images']: image = Image.open(io.BytesIO(base64.b64decode(i.split(\",\",1)[0]))) png_payload = { \"image\": \"data:image/png;base64,\" + i } response2 = requests.post(url=f'{url}/sdapi/v1/png-info', json=png_payload) pnginfo = PngImagePlugin.PngInfo() pnginfo.add_text(\"parameters\", response2.json().get(\"info\")) image.save('output.png', pnginfo=pnginfo) Импорт вещей, которые мне нужны определить URL-адрес и полезную нагрузку для отправки отправить указанную полезную нагрузку на указанный URL-адрес через API в цикле захватите “изображения” и расшифруйте их для каждого изображения отправьте его в API информации png и получите эту информацию обратно определите плагин для добавления информации png, затем добавьте информацию png, которую я определил в него в конце сохраните изображение с информацией png Примечание к \"override_settings\". Целью этой конечной точки является переопределение настроек веб-интерфейса для одного запроса, например пропуска CLIP. Настройки, которые можно передать в этот параметр, видны здесь, в URL-адресе /docs. Вы можете развернуть вкладку, и API предоставит список. Есть несколько способов добавить это значение к полезной нагрузке, но я делаю это так. Я продемонстрирую с «filter_nsfw» и «CLIP_stop_at_last_layers». payload = { \"prompt\": \"cirno\", \"steps\": 20 } override_settings = {} override_settings[\"filter_nsfw\"] = true override_settings[\"CLIP_stop_at_last_layers\"] = 2 override_payload = { \"override_settings\": override_settings } payload.update(override_payload) иметь нормальную грузоподъемность после этого инициализировать словарь (я называю его “override_settings”, но может не самое удачное название) тогда я могу добавить столько пар ключ: значение, сколько захочу сделать новую полезную нагрузку только с этим параметром обновить исходную полезную нагрузку, чтобы добавить к ней эту Таким образом, в этом случае, когда я отправляю полезную нагрузку, я должен получить «cirno» на 20 шагах, с пропуском CLIP на 2, а также с включенным фильтром NSFW. Для определенных настроек или ситуаций вы можете захотеть, чтобы ваши изменения остались. Для этого вы можете отправить сообщение в конечную точку API /sdapi/v1/options Мы можем использовать то, что мы узнали до сих пор, и легко настроить код для этого. Вот пример: url = \"http://127.0.0.1:7860\" option_payload = { \"sd_model_checkpoint\": \"Anything-V3.0-pruned.ckpt [2700c435]\", \"CLIP_stop_at_last_layers\": 2 } response = requests.post(url=f'{url}/sdapi/v1/options', json=option_payload) После отправки этой полезной нагрузки в API модель должна переключиться на ту, которую я установил, и установить пропуск CLIP на 2. Повторяю, это отличается от «override_settings», потому что это изменение будет сохраняться, в то время как «override_settings» предназначен для одного запроса. . Обратите внимание, что если вы меняете sd_model_checkpoint, значением должно быть имя контрольной точки, как оно отображается в веб-интерфейсе. На это можно ссылаться с помощью этой конечной точки API (так же, как мы ссылаемся на API «опций») «Название» (имя и хэш) — это то, что вы хотите использовать. Это на момент фиксации 47a44c7 Для более полной реализации фронтенда мой бот Discord находится здесь, если кто хочет посмотреть на него в качестве примера. Большая часть действий происходит в файле stablecog.py. Есть много комментариев, объясняющих, что делает каждый код. Это руководство можно найти на странице обсуждения. Кроме того, ознакомьтесь с этой клиентской библиотекой API Python для webui: https://github.com/mix1009/sdwebuiapi."
  },"/sdwui-docs/install/": {
    "title": "Установить",
    "keywords": "Getting started",
    "url": "/sdwui-docs/install/",
    "body": "Убедитесь, что необходимые зависимости соблюдены, и следуйте инструкциям, доступным для обоих NVidia (рекомендуется) и AMD графические процессоры. В качестве альтернативы используйте онлайн-сервисы (например, Google Colab): Онлайн-сервисы Автоматическая установка в Windows Установите Python 3.10.6, отметив «Добавить Python в PATH». Установите git. Загрузите репозиторий stable-diffusion-webui, например, запустив git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git. Поместите model.ckpt в каталог models (см. зависимости, чтобы узнать, где его взять). *(Необязательно)* Поместите GFPGANv1.4.pth в базовый каталог вместе с webui.py (см. зависимости для того, чтобы узнать, где его взять). Запустите webui-user.bat из проводника Windows как обычный пользователь без прав администратора. Автоматическая установка в Linux Установите зависимости: # Debian-based: sudo apt install wget git python3 python3-venv # Red Hat-based: sudo dnf install wget git python3 # Arch-based: sudo pacman -S wget git python3 Чтобы установить в /home/$(whoami)/stable-diffusion-webui/, запустите: bash &lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh) Установка на Apple Silicon Найдите инструкции здесь."
  },"/sdwui-docs/pages/ru/Optimizations/": {
    "title": "Оптимизации",
    "keywords": "Guides",
    "url": "/sdwui-docs/pages/ru/Optimizations/",
    "body": "Ряд оптимизаций можно включить с помощью аргументов командной строки: аргумент командной строки объяснение --xformers Используйте библиотеку xformers. Большое улучшение потребления памяти и скорости. Версия для Windows устанавливает двоичные файлы, поддерживаемые C43H66N12O12S2. Будет включен только для небольшого подмножества конфигурации, потому что для этого у нас есть двоичные файлы. Документация --force-enable-xformers Включает xformers выше, независимо от того, считает ли программа, что вы можете запустить его или нет. Не сообщайте об ошибках, которые вы получаете при запуске этого. --опт-расщепление-внимание Оптимизация уровня перекрестного внимания значительно сокращает использование памяти практически бесплатно (некоторые сообщают об улучшении производительности с ее помощью). Черная магия. Включено по умолчанию для torch.cuda, который включает карты NVidia и AMD. --disable-opt-split-tention Отключает приведенную выше оптимизацию. --опт-расщепление-внимание-v1 Использует более старую версию приведенной выше оптимизации, которая не так требовательна к памяти (будет использовать меньше видеопамяти, но будет больше ограничивать максимальный размер изображений, которые вы можете сделать). --медврам Заставляет модель Stable Diffusion потреблять меньше видеопамяти, разделяя ее на три части: cond (для преобразования текста в числовое представление), first_stage (для преобразования изображения в скрытое пространство и обратно) и unet (для фактического удаления шума из скрытого пространства) и делая это так, что только один всегда находится в VRAM, отправляя другие в RAM CPU. Снижает производительность, но только немного, за исключением случаев, когда включен предварительный просмотр в реальном времени. --lowvram Еще более тщательная оптимизация вышеперечисленного, разбиение unet на множество модулей, а в VRAM хранится только один модуль. Разрушительный для производительности. *do-not-batch-cond-uncond Предотвращает пакетирование положительных и отрицательных запросов во время выборки, что по существу позволяет вам работать с размером пакета 0,5, экономя много памяти. Снижает производительность. Не параметр командной строки, а оптимизация, неявно включенная с помощью --medvram или --lowvram. --always-batch-cond-uncond Отключает приведенную выше оптимизацию. Имеет смысл только вместе с --medvram или --lowvram --opt-channelslast Изменяет тип памяти факела для стабильной диффузии на последние каналы. Эффекты тщательно не изучены. Дополнительные советы (Windows): https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/3889 Отключить аппаратное планирование графического процессора. отключить аппаратное ускорение браузера Зайдите в панель управления nvidia, параметры 3d и измените профиль мощности на «максимальную производительность»."
  },"/sdwui-docs/2022-12-27-my-new-post.html": {
    "title": "Release note example",
    "keywords": "",
    "url": "/sdwui-docs/2022-12-27-my-new-post.html",
    "body": "Test"
  }}
